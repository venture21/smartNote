"""
íšŒì˜ë¡ TTS-STT ì •í™•ë„ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (Google Gemini STT ì‚¬ìš©)

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
1. txt íŒŒì¼ì—ì„œ íšŒì˜ë¡ ìŠ¤í¬ë¦½íŠ¸ ì½ê¸°
2. OpenAI TTS APIë¡œ ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„±
3. Google Gemini STT APIë¡œ ì˜¤ë””ì˜¤ ì¸ì‹í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì‹ ë¢°ë„ í¬í•¨)
4. ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ì™€ ì¸ì‹ëœ ìŠ¤í¬ë¦½íŠ¸ ë¹„êµí•˜ì—¬ ì •í™•ë„ ì¸¡ì •
"""

import os
import re
import io
import json
import pandas as pd
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from openai import OpenAI
from pydub import AudioSegment
from google import genai
from google.genai import types
import argparse
from difflib import SequenceMatcher


# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


# OpenAI TTS ì„¤ì •
TTS_MODEL = "tts-1-hd"  # ë˜ëŠ” "tts-1"
SPEAKER_VOICES = {
    "Speaker 1": "alloy",  # ì¤‘ì„±ì ì¸ ìŒì„±
    "Speaker 2": "echo",   # ë‚¨ì„±ì ì¸ ìŒì„±
    "Speaker 3": "fable",  # ì˜êµ­ì‹ ì–µì–‘
    "Speaker 4": "onyx",   # ê¹Šì€ ë‚¨ì„± ìŒì„±
}


def parse_meeting_text(text_content: str) -> List[Dict[str, str]]:
    """
    íšŒì˜ë¡ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•˜ì—¬ í™”ìì™€ ëŒ€í™” ë‚´ìš©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        text_content: íšŒì˜ë¡ í…ìŠ¤íŠ¸ (í˜•ì‹: "Speaker 1: ì•ˆë…•í•˜ì„¸ìš”")

    Returns:
        íŒŒì‹±ëœ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ [{"speaker": "Speaker 1", "transcript": "ì•ˆë…•í•˜ì„¸ìš”"}, ...]
    """
    parsed_data = []
    file_like_object = io.StringIO(text_content)

    for line in file_like_object:
        clean_line = line.strip()

        # ë¹ˆ ì¤„ì€ ê±´ë„ˆëœ€
        if not clean_line:
            continue

        # "Speaker X: " í˜•ì‹ íŒŒì‹±
        parts = clean_line.split(": ", 1)

        if len(parts) == 2:
            speaker = parts[0].strip()
            transcript = parts[1].strip()
            parsed_data.append({"speaker": speaker, "transcript": transcript})

    return parsed_data


def merge_consecutive_speakers(parsed_data: List[Dict[str, str]]) -> List[Dict[str, str]]:
    """
    ì—°ì†ì ìœ¼ë¡œ ë™ì¼í•œ í™”ìì˜ ë°œì–¸ì„ í•˜ë‚˜ë¡œ í•©ì¹©ë‹ˆë‹¤.

    Args:
        parsed_data: íŒŒì‹±ëœ íšŒì˜ë¡ ë°ì´í„° [{"speaker": "Speaker 1", "transcript": "ì•ˆë…•"}, ...]

    Returns:
        ë³‘í•©ëœ íšŒì˜ë¡ ë°ì´í„°
    """
    if not parsed_data:
        return []

    merged_data = []
    current_item = parsed_data[0].copy()

    for next_item in parsed_data[1:]:
        if current_item['speaker'] == next_item['speaker']:
            # ë™ì¼ í™”ìë©´ transcriptë¥¼ í•©ì¹¨ (ê³µë°±ìœ¼ë¡œ êµ¬ë¶„)
            current_item['transcript'] += ' ' + next_item['transcript']
        else:
            # í™”ìê°€ ë‹¤ë¥´ë©´ í˜„ì¬ í•­ëª©ì„ ê²°ê³¼ì— ì¶”ê°€í•˜ê³  ë‹¤ìŒ í•­ëª©ìœ¼ë¡œ ì´ë™
            merged_data.append(current_item)
            current_item = next_item.copy()

    # ë§ˆì§€ë§‰ í•­ëª© ì¶”ê°€
    merged_data.append(current_item)

    print(f"âœ… ì—°ì† í™”ì ë³‘í•©: {len(parsed_data)}ê°œ â†’ {len(merged_data)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
    return merged_data


def save_to_csv(parsed_data: List[Dict[str, str]], filename: str) -> pd.DataFrame:
    """
    íŒŒì‹±ëœ íšŒì˜ë¡ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        parsed_data: íŒŒì‹±ëœ íšŒì˜ë¡ ë°ì´í„°
        filename: ì €ì¥í•  CSV íŒŒì¼ëª…

    Returns:
        ì €ì¥ëœ DataFrame
    """
    df = pd.DataFrame(parsed_data)
    df.to_csv(filename, index=False, encoding="utf-8-sig")
    print(f"âœ… CSV íŒŒì¼ ìƒì„±: {filename}")
    return df


def generate_audio_from_text(conversation: str, output_file: str) -> bool:
    """
    OpenAI TTS APIë¥¼ ì‚¬ìš©í•˜ì—¬ íšŒì˜ë¡ í…ìŠ¤íŠ¸ë¥¼ ì˜¤ë””ì˜¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        conversation: íšŒì˜ë¡ í…ìŠ¤íŠ¸
        output_file: ì¶œë ¥ ì˜¤ë””ì˜¤ íŒŒì¼ëª…

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

    # ëŒ€í™” ë‚´ìš© íŒŒì‹±
    dialogue_blocks = conversation.strip().split("\n")
    dialogue_parts = []

    for block in dialogue_blocks:
        if block.strip():
            match = re.match(r"(Speaker \d+): (.*)", block, re.DOTALL)
            if match:
                speaker = match.group(1)
                dialogue = match.group(2)
                dialogue_parts.append({"speaker": speaker, "dialogue": dialogue})

    # ê° íŒŒíŠ¸ë³„ ì˜¤ë””ì˜¤ ìƒì„±
    all_audio_segments = []

    for part in dialogue_parts:
        speaker = part["speaker"]
        dialogue = part["dialogue"]
        voice_name = SPEAKER_VOICES.get(speaker, "alloy")

        print(f"ğŸ¤ {speaker} ìŒì„± ìƒì„± ì¤‘ (voice: {voice_name})...")

        try:
            response = client.audio.speech.create(
                model=TTS_MODEL,
                voice=voice_name,
                input=dialogue,
                response_format="wav",
            )

            audio_data = response.content
            audio_segment = AudioSegment.from_file(io.BytesIO(audio_data), format="wav")
            all_audio_segments.append(audio_segment)
            print("  âœ… ì„±ê³µ")

        except Exception as e:
            print(f"  âŒ ì‹¤íŒ¨: {e}")
            return False

    # ëª¨ë“  ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ê²°í•©
    if all_audio_segments:
        print("\nğŸ”— ì˜¤ë””ì˜¤ ê²°í•© ì¤‘...")
        combined_audio = all_audio_segments[0]
        for segment in all_audio_segments[1:]:
            combined_audio += segment

        combined_audio.export(output_file, format="wav")
        print(f"âœ… ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„±: {output_file}")
        return True
    else:
        print("âŒ ì˜¤ë””ì˜¤ ìƒì„± ì‹¤íŒ¨")
        return False


def recognize_audio_with_gemini(audio_file: str, api_key: str = None) -> Optional[List[Dict[str, Any]]]:
    """
    Google Gemini STT APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        audio_file: ì¸ì‹í•  ì˜¤ë””ì˜¤ íŒŒì¼ëª…
        api_key: Google API í‚¤ (ì„ íƒ)

    Returns:
        ì¸ì‹ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” None
    """
    print(f"\nğŸ§ Gemini STT APIë¡œ ìŒì„± ì¸ì‹ ì¤‘: {audio_file}")

    try:
        # Client ìƒì„±
        if api_key:
            client = genai.Client(api_key=api_key)
        else:
            client = genai.Client()

        print(f"ğŸ“¤ '{audio_file}' íŒŒì¼ì„ ì—…ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤...")

        # ë¡œì»¬ íŒŒì¼ì„ ë°”ì´ë„ˆë¦¬ë¡œ ì½ê¸°
        with open(audio_file, "rb") as f:
            file_bytes = f.read()

        # íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ MIME íƒ€ì… ê²°ì •
        file_ext = os.path.splitext(audio_file)[1].lower()
        mime_type_map = {
            ".wav": "audio/wav",
            ".mp3": "audio/mp3",
            ".m4a": "audio/mp4",
            ".flac": "audio/flac",
            ".ogg": "audio/ogg",
        }
        mime_type = mime_type_map.get(file_ext, "audio/wav")

        print(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ (íƒ€ì…: {mime_type})")

        prompt = """
ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ íšŒì˜ë¡ ì‘ì„±ìì…ë‹ˆë‹¤. ì œê³µëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë“£ê³  ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•´ ì£¼ì‹­ì‹œì˜¤:
1. ì „ì²´ ëŒ€í™”ë¥¼ ì •í™•í•˜ê²Œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
2. ê° ë°œí™”ì— ëŒ€í•´ í™”ìë¥¼ ìˆ«ìë¡œ êµ¬ë¶„í•©ë‹ˆë‹¤. ë°œí™”ìì˜ ë“±ì¥ ìˆœì„œëŒ€ë¡œ ë²ˆí˜¸ë¥¼ í• ë‹¹í•©ë‹ˆë‹¤. ì°¸ê³ ë¡œ, í˜„ì¬ ì˜¤ë””ì˜¤ì˜ í™”ììˆ˜ëŠ” ì´ 4ëª…ì…ë‹ˆë‹¤. í™”ìì˜ ìˆ«ìëŠ” 4ë¥¼ ë„˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
3. ê° ë°œí™”ì— ëŒ€í•´ ìŒì„± ì¸ì‹ì˜ ì‹ ë¢°ë„ë¥¼ 0.0~1.0 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤. ìŒì§ˆ, ë°œìŒ ëª…í™•ë„, ë°°ê²½ ì†ŒìŒ ë“±ì„ ê³ ë ¤í•˜ì—¬ ì¶”ì •í•©ë‹ˆë‹¤.
4. ìµœì¢… ê²°ê³¼ëŠ” ì•„ë˜ì˜ JSON í˜•ì‹ê³¼ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤. ê° JSON ê°ì²´ëŠ” 'speaker', 'start_time_seconds', 'confidence', 'transcript' í‚¤ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
5. speakerê°€ ë™ì¼í•œ ê²½ìš° í•˜ë‚˜ì˜ í–‰ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤. í•˜ë‚˜ì˜ í–‰ìœ¼ë¡œ ë§Œë“œëŠ” ê²½ìš° 'start_time_seconds' ê°’ì€ ì œì¼ ì•ì˜ í–‰ì˜ ì‹œê°„ì„ ì‚¬ìš©í•˜ê³ , confidenceëŠ” í‰ê· ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:
[
    {
        "speaker": 1,
        "start_time_seconds": 0.0,
        "confidence": 0.95,
        "transcript": "ì•ˆë…•í•˜ì„¸ìš”. íšŒì˜ë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤."
    },
    {
        "speaker": 2,
        "start_time_seconds": 5.2,
        "confidence": 0.92,
        "transcript": "ë„¤, ì¢‹ìŠµë‹ˆë‹¤."
    }
]

JSON ë°°ì—´ë§Œ ì¶œë ¥í•˜ê³ , ì¶”ê°€ ì„¤ëª…ì´ë‚˜ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
"""

        # ëª¨ë¸ì— ë©€í‹°ëª¨ë‹¬ í”„ë¡¬í”„íŠ¸ ì „ì†¡
        print("ğŸ¤– Gemini 2.5 Proë¡œ ìŒì„± ì¸ì‹ ì¤‘...")

        response = client.models.generate_content(
            model="gemini-2.5-pro",
            contents=[
                prompt,
                types.Part.from_bytes(
                    data=file_bytes,
                    mime_type=mime_type,
                ),
            ],
        )

        print("âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ")

        # ê²°ê³¼ ì •ë¦¬
        cleaned_response = response.text.strip()
        cleaned_response = cleaned_response.replace("```json", "").replace("```", "").strip()

        # JSON íŒŒì‹±
        try:
            result_list = json.loads(cleaned_response)
            return result_list
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            print(f"ì›ë³¸ ì‘ë‹µ: {cleaned_response[:500]}")
            return None

    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - {audio_file}")
        return None
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def calculate_accuracy(original_df: pd.DataFrame, recognized_segments: List[Dict[str, Any]]) -> Dict[str, float]:
    """
    ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ì™€ ì¸ì‹ëœ ìŠ¤í¬ë¦½íŠ¸ì˜ ì •í™•ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

    Args:
        original_df: ì›ë³¸ íšŒì˜ë¡ DataFrame
        recognized_segments: ì¸ì‹ëœ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸

    Returns:
        ì •í™•ë„ ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
    """
    # ì¸ì‹ëœ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
    recognized_df = pd.DataFrame(recognized_segments)

    # í™”ì ë²ˆí˜¸ ì •ê·œí™” (Speaker ì œê±°)
    original_speakers = original_df['speaker'].str.replace("Speaker ", "", regex=False).astype(int)
    recognized_speakers = recognized_df['speaker'].astype(int)

    # í™”ì ì¸ì‹ ì •í™•ë„ (ê¸¸ì´ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìµœì†Œ ê¸¸ì´ë§Œí¼ë§Œ ë¹„êµ)
    min_len = min(len(original_speakers), len(recognized_speakers))
    speaker_accuracy = (original_speakers[:min_len] == recognized_speakers[:min_len]).sum() / min_len * 100

    # í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°
    text_similarities = []
    for i in range(min_len):
        original_text = original_df.iloc[i]['transcript']
        recognized_text = recognized_df.iloc[i]['transcript']

        # SequenceMatcherë¥¼ ì‚¬ìš©í•œ ìœ ì‚¬ë„ ê³„ì‚°
        similarity = SequenceMatcher(None, original_text, recognized_text).ratio() * 100
        text_similarities.append(similarity)

    avg_text_similarity = sum(text_similarities) / len(text_similarities) if text_similarities else 0

    # ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜ ì¼ì¹˜ìœ¨
    segment_match_rate = min_len / max(len(original_df), len(recognized_df)) * 100

    # ì „ì²´ í…ìŠ¤íŠ¸ ë¹„êµ
    original_full_text = " ".join(original_df['transcript'].tolist())
    recognized_full_text = " ".join(recognized_df['transcript'].tolist())
    overall_similarity = SequenceMatcher(None, original_full_text, recognized_full_text).ratio() * 100

    # í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
    avg_confidence = 0.0
    if 'confidence' in recognized_df.columns:
        avg_confidence = recognized_df['confidence'].mean()

    return {
        "í™”ì_ì¸ì‹_ì •í™•ë„": round(speaker_accuracy, 2),
        "í‰ê· _í…ìŠ¤íŠ¸_ìœ ì‚¬ë„": round(avg_text_similarity, 2),
        "ì „ì²´_í…ìŠ¤íŠ¸_ìœ ì‚¬ë„": round(overall_similarity, 2),
        "ì„¸ê·¸ë¨¼íŠ¸_ì¼ì¹˜ìœ¨": round(segment_match_rate, 2),
        "í‰ê· _ì‹ ë¢°ë„": round(avg_confidence, 2),
        "ì›ë³¸_ì„¸ê·¸ë¨¼íŠ¸_ìˆ˜": len(original_df),
        "ì¸ì‹_ì„¸ê·¸ë¨¼íŠ¸_ìˆ˜": len(recognized_df)
    }


def save_comparison_csv(original_df: pd.DataFrame, recognized_segments: List[Dict[str, Any]], output_file: str):
    """
    ì›ë³¸ê³¼ ì¸ì‹ ê²°ê³¼ë¥¼ ë¹„êµí•œ CSV íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        original_df: ì›ë³¸ íšŒì˜ë¡ DataFrame
        recognized_segments: ì¸ì‹ëœ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
        output_file: ì¶œë ¥ CSV íŒŒì¼ëª…
    """
    # ì¸ì‹ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
    recognized_df = pd.DataFrame(recognized_segments)

    # ì»¬ëŸ¼ëª… ë³€ê²½
    recognized_df = recognized_df.rename(columns={
        'speaker': 'recognized_speaker',
        'transcript': 'recognized_text',
        'start_time_seconds': 'start_time'
    })

    # ì›ë³¸ê³¼ ì¸ì‹ ê²°ê³¼ ë³‘í•©
    comparison_df = pd.concat([
        original_df.reset_index(drop=True),
        recognized_df.reset_index(drop=True)
    ], axis=1)

    # í™”ì ë²ˆí˜¸ ì •ê·œí™”
    comparison_df['speaker_num'] = comparison_df['speaker'].str.replace("Speaker ", "", regex=False).astype(int)

    # ì €ì¥
    comparison_df.to_csv(output_file, index=False, encoding="utf-8-sig")
    print(f"âœ… ë¹„êµ ê²°ê³¼ ì €ì¥: {output_file}")


def print_accuracy_report(accuracy_metrics: Dict[str, float]):
    """
    ì •í™•ë„ ë³´ê³ ì„œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.

    Args:
        accuracy_metrics: ì •í™•ë„ ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
    """
    print("\n" + "="*60)
    print("ğŸ“Š ì •í™•ë„ ë¶„ì„ ê²°ê³¼ (Gemini STT)")
    print("="*60)
    print(f"í™”ì ì¸ì‹ ì •í™•ë„:      {accuracy_metrics['í™”ì_ì¸ì‹_ì •í™•ë„']:.2f}%")
    print(f"í‰ê·  í…ìŠ¤íŠ¸ ìœ ì‚¬ë„:    {accuracy_metrics['í‰ê· _í…ìŠ¤íŠ¸_ìœ ì‚¬ë„']:.2f}%")
    print(f"ì „ì²´ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„:    {accuracy_metrics['ì „ì²´_í…ìŠ¤íŠ¸_ìœ ì‚¬ë„']:.2f}%")
    print(f"ì„¸ê·¸ë¨¼íŠ¸ ì¼ì¹˜ìœ¨:       {accuracy_metrics['ì„¸ê·¸ë¨¼íŠ¸_ì¼ì¹˜ìœ¨']:.2f}%")
    print(f"í‰ê·  ì‹ ë¢°ë„:           {accuracy_metrics['í‰ê· _ì‹ ë¢°ë„']:.2f}")
    print(f"ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜:      {accuracy_metrics['ì›ë³¸_ì„¸ê·¸ë¨¼íŠ¸_ìˆ˜']}")
    print(f"ì¸ì‹ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜:      {accuracy_metrics['ì¸ì‹_ì„¸ê·¸ë¨¼íŠ¸_ìˆ˜']}")
    print("="*60)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="íšŒì˜ë¡ TTS-STT ì •í™•ë„ í…ŒìŠ¤íŠ¸ (Gemini STT)")
    parser.add_argument("input_txt", help="ì…ë ¥ íšŒì˜ë¡ txt íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--output-prefix", default="meeting", help="ì¶œë ¥ íŒŒì¼ëª… ì ‘ë‘ì‚¬ (ê¸°ë³¸ê°’: meeting)")
    parser.add_argument("--api-key", help="Google API í‚¤ (í™˜ê²½ë³€ìˆ˜ ìš°ì„ )", default=None)

    args = parser.parse_args()

    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    input_txt = args.input_txt
    output_prefix = args.output_prefix
    csv_file = f"{output_prefix}.csv"
    audio_file = f"{output_prefix}.wav"
    comparison_file = f"{output_prefix}_comparison.csv"

    # API í‚¤ ì„¤ì •
    api_key = args.api_key or os.environ.get("GOOGLE_API_KEY")

    print("="*60)
    print("ğŸ¯ íšŒì˜ë¡ TTS-STT ì •í™•ë„ í…ŒìŠ¤íŠ¸ ì‹œì‘ (Gemini STT)")
    print("="*60)
    print(f"ì…ë ¥ íŒŒì¼: {input_txt}")
    print(f"ì¶œë ¥ CSV: {csv_file}")
    print(f"ì¶œë ¥ ì˜¤ë””ì˜¤: {audio_file}")
    print(f"ë¹„êµ ê²°ê³¼: {comparison_file}")
    print("="*60)

    # 1. txt íŒŒì¼ ì½ê¸°
    print("\nğŸ“– Step 1: íšŒì˜ë¡ í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸°")
    if not os.path.exists(input_txt):
        print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - {input_txt}")
        return

    with open(input_txt, "r", encoding="utf-8") as f:
        meeting_text = f.read()

    print(f"âœ… í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸° ì™„ë£Œ: {len(meeting_text)} ë¬¸ì")

    # 2. í…ìŠ¤íŠ¸ íŒŒì‹± ë° CSV ì €ì¥
    print("\nğŸ“ Step 2: í…ìŠ¤íŠ¸ íŒŒì‹± ë° ì—°ì† í™”ì ë³‘í•©")
    parsed_data = parse_meeting_text(meeting_text)
    print(f"âœ… íŒŒì‹± ì™„ë£Œ: {len(parsed_data)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")

    # ì—°ì†ëœ ë™ì¼ í™”ì ë³‘í•©
    merged_data = merge_consecutive_speakers(parsed_data)

    # CSV ì €ì¥
    original_df = save_to_csv(merged_data, csv_file)

    # 3. OpenAI TTSë¡œ ì˜¤ë””ì˜¤ ìƒì„±
    print("\nğŸµ Step 3: OpenAI TTSë¡œ ì˜¤ë””ì˜¤ ìƒì„±")
    success = generate_audio_from_text(meeting_text, audio_file)
    if not success:
        print("âŒ ì˜¤ë””ì˜¤ ìƒì„± ì‹¤íŒ¨")
        return

    # 4. Gemini STT APIë¡œ ìŒì„± ì¸ì‹
    print("\nğŸ§ Step 4: Gemini STT APIë¡œ ìŒì„± ì¸ì‹")
    result = recognize_audio_with_gemini(audio_file, api_key)
    if not result:
        print("âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨")
        return

    print(f"âœ… ì¸ì‹ ì™„ë£Œ: {len(result)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")

    # 5. ì •í™•ë„ ê³„ì‚°
    print("\nğŸ” Step 5: ì •í™•ë„ ê³„ì‚°")
    accuracy_metrics = calculate_accuracy(original_df, result)

    # 6. ë¹„êµ ê²°ê³¼ ì €ì¥
    print("\nğŸ’¾ Step 6: ë¹„êµ ê²°ê³¼ ì €ì¥")
    save_comparison_csv(original_df, result, comparison_file)

    # 7. ê²°ê³¼ ì¶œë ¥
    print_accuracy_report(accuracy_metrics)

    print("\nâœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")


if __name__ == "__main__":
    main()
