"""
STT (Speech-to-Text) ëª¨ë“ˆ - Gemini API ì‚¬ìš©
"""

import os
import logging
import time
import json
import tempfile
from difflib import SequenceMatcher
from pydub import AudioSegment
from google import genai
from google.genai import types


def get_gemini_client():
    """Gemini í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    api_key = os.environ.get("GOOGLE_API_KEY")
    if api_key:
        return genai.Client(api_key=api_key)
    else:
        return genai.Client()


def recognize_with_gemini(audio_path, task_id=None, audio_duration=None):
    """
    Google Gemini STT APIë¡œ ìŒì„± ì¸ì‹ ë° ì–¸ì–´ ê°ì§€

    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        task_id: ì§„í–‰ ìƒí™© ì¶”ì ìš© ID (optional)
        audio_duration: ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ì´ ê¸¸ì´ (ì´ˆ) (optional)

    Returns:
        tuple: (segments, processing_time, detected_language) ë˜ëŠ” (None, 0.0, 'unknown') on error
    """
    from modules.utils import update_progress, parse_mmss_to_seconds

    start_time = time.time()

    try:
        if task_id:
            update_progress(task_id, "stt", 0, "Gemini STT ì‹œì‘")

        logging.info(f"ğŸ§ Gemini STT APIë¡œ ìŒì„± ì¸ì‹ ì¤‘: {audio_path}")

        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(audio_path):
            error_msg = f"ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {audio_path}"
            logging.error(f"âŒ {error_msg}")
            if task_id:
                update_progress(task_id, "stt", 100, f"ì˜¤ë¥˜: {error_msg}")
            return None, 0.0, "unknown"

        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = os.path.getsize(audio_path)
        file_size_mb = file_size / (1024 * 1024)
        logging.info(f"ğŸ“ íŒŒì¼ í¬ê¸°: {file_size_mb:.2f} MB")

        if file_size == 0:
            error_msg = f"ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {audio_path}"
            logging.error(f"âŒ {error_msg}")
            if task_id:
                update_progress(task_id, "stt", 100, f"ì˜¤ë¥˜: {error_msg}")
            return None, 0.0, "unknown"

        client = get_gemini_client()

        with open(audio_path, "rb") as f:
            file_bytes = f.read()

        file_ext = os.path.splitext(audio_path)[1].lower()
        mime_type_map = {
            ".wav": "audio/wav",
            ".mp3": "audio/mp3",
            ".m4a": "audio/mp4",
            ".flac": "audio/flac",
            ".ogg": "audio/ogg",
        }
        mime_type = mime_type_map.get(file_ext, "audio/mp3")
        logging.info(f"ğŸµ MIME íƒ€ì…: {mime_type}, í™•ì¥ì: {file_ext}")

        prompt = """
ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ íšŒì˜ë¡ ì‘ì„±ìì…ë‹ˆë‹¤. ì œê³µëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë“£ê³  ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•´ ì£¼ì‹­ì‹œì˜¤:

ì‘ì—… ìš”êµ¬ì‚¬í•­:
1. ì „ì²´ ëŒ€í™”ë¥¼ ì •í™•í•˜ê²Œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

2. **í™”ì ë¶„ë¦¬ (ë§¤ìš° ì¤‘ìš”)**:
   - ê° ë°œí™”ì— ëŒ€í•´ í™”ìë¥¼ ìˆ«ìë¡œ êµ¬ë¶„í•©ë‹ˆë‹¤
   - ë°œí™”ìì˜ ë“±ì¥ ìˆœì„œëŒ€ë¡œ ë²ˆí˜¸ë¥¼ í• ë‹¹í•©ë‹ˆë‹¤ (1, 2, 3, ...)
   - ìŒì„±ì˜ í†¤, í”¼ì¹˜, ë§íˆ¬ì˜ ì°¨ì´ë¥¼ ì£¼ì˜ê¹Šê²Œ ë¶„ì„í•˜ì—¬ ì •í™•í•˜ê²Œ í™”ìë¥¼ êµ¬ë¶„í•˜ì„¸ìš”
   - í™”ìê°€ ë°”ë€Œë©´ ë°˜ë“œì‹œ ìƒˆë¡œìš´ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë¶„ë¦¬í•˜ì„¸ìš”

3. ê° ë°œí™”ì— ëŒ€í•´ ìŒì„± ì¸ì‹ì˜ ì‹ ë¢°ë„ë¥¼ 0.0~1.0 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.

4. start_time_mmssëŠ” ë°˜ë“œì‹œ "ì‹œ:ë¶„:ì´ˆ" í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
   ì˜ˆì‹œ: "0:00:05", "0:01:23", "1:05:30"

5. ë°°ê²½ìŒì•…ê³¼ ë°œí™”ìì˜ ëª©ì†Œë¦¬ê°€ ì„ì¸ ê²½ìš° ëª©ì†Œë¦¬ë§Œ ì˜ êµ¬ë³„í•˜ì—¬ ê°€ì ¸ì˜¨ë‹¤.

6. **ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ ì œí•œ**:
   - ë™ì¼ í™”ìì˜ ì—°ì† ë°œí™”ë¥¼ í•˜ë‚˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ê·¸ë£¹í™”í•©ë‹ˆë‹¤
   - ë‹¨, í•˜ë‚˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ê°€ 4ê°œ ë¬¸ì¥ì„ ì´ˆê³¼í•˜ë©´ ì ì ˆí•œ ìœ„ì¹˜ì—ì„œ ë¶„ë¦¬í•©ë‹ˆë‹¤

7. ëŒ€í™” ë‚´ìš©ì— ëŒ€í•œ ëˆ„ë½ì´ ë°œìƒí•˜ì§€ ì•Šê²Œ ì£¼ì˜í•˜ì„¸ìš”.
8. ì„¸ê·¸ë¨¼íŠ¸ì˜ ì‹œì‘ ì‹œê°„ì„ ì •í™•í•˜ê²Œ ê¸°ë¡í•´ì£¼ì„¸ìš”.

ì¤‘ìš”: ë°˜ë“œì‹œ ì•„ë˜ì˜ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ê° ê°ì²´ëŠ” speaker, start_time_mmss, confidence, text í‚¤ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

ì¶œë ¥ í˜•ì‹ (ì •í™•íˆ ì´ êµ¬ì¡°ë¥¼ ë”°ë¥´ì„¸ìš”):
[
    {
        "speaker": 1,
        "start_time_mmss": "0:00:00",
        "confidence": 0.95,
        "text": "ì•ˆë…•í•˜ì„¸ìš”. íšŒì˜ë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤."
    },
    {
        "speaker": 2,
        "start_time_mmss": "0:00:05",
        "confidence": 0.92,
        "text": "ë„¤, ì¢‹ìŠµë‹ˆë‹¤."
    }
]

ì£¼ì˜ì‚¬í•­:
- ë°˜ë“œì‹œ ìœ íš¨í•œ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
- ì¶”ê°€ ì„¤ëª…, ì£¼ì„, ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì—†ì´ ìˆœìˆ˜ JSONë§Œ ì¶œë ¥
- ëª¨ë“  ë¬¸ìì—´ì€ í°ë”°ì˜´í‘œ(")ë¡œ ê°ì‹¸ê¸°
- ë§ˆì§€ë§‰ í•­ëª© ë’¤ì—ëŠ” ì‰¼í‘œ ì—†ìŒ
"""

        logging.info("ğŸ¤– Gemini 2.5 Proë¡œ ìŒì„± ì¸ì‹ ì¤‘...")

        try:
            response = client.models.generate_content(
                model="gemini-2.5-pro",
                contents=[
                    prompt,
                    types.Part.from_bytes(
                        data=file_bytes,
                        mime_type=mime_type,
                    ),
                ],
                config=types.GenerateContentConfig(
                    max_output_tokens=250000,  # ê¸´ ëŒ€í™”ë¡ì„ ìœ„í•´ ì¶œë ¥ ê¸¸ì´ ì¦ê°€
                    temperature=0.1,  # ì •í™•ì„±ì„ ìœ„í•´ ë‚®ì€ temperature ì‚¬ìš©
                    response_mime_type="application/json",  # JSON í˜•ì‹ ê°•ì œ
                ),
            )
        except Exception as api_error:
            error_type = type(api_error).__name__
            error_msg = str(api_error)
            logging.error(f"âŒ Gemini API í˜¸ì¶œ ì˜¤ë¥˜ [{error_type}]: {error_msg}")
            logging.error(f"   íŒŒì¼: {audio_path} ({file_size_mb:.2f} MB)")
            logging.error(f"   MIME íƒ€ì…: {mime_type}")

            if task_id:
                update_progress(
                    task_id, "stt", 100, f"API ì˜¤ë¥˜ [{error_type}]: {error_msg[:100]}"
                )

            import traceback

            traceback.print_exc()
            return None, 0.0, "unknown"

        if task_id:
            update_progress(task_id, "stt", 50, "Gemini ì‘ë‹µ íŒŒì‹± ì¤‘")

        # ì‘ë‹µ ê²€ì¦
        if not response or not hasattr(response, "text") or response.text is None:
            error_msg = "Gemini APIê°€ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤"
            logging.error(f"âŒ {error_msg}")
            logging.error(f"   íŒŒì¼: {audio_path} ({file_size_mb:.2f} MB)")

            # response ê°ì²´ ë””ë²„ê¹… ì •ë³´
            if response:
                logging.error(f"   response type: {type(response)}")
                logging.error(f"   response attributes: {dir(response)}")
                if hasattr(response, "candidates"):
                    logging.error(f"   candidates: {response.candidates}")
                if hasattr(response, "prompt_feedback"):
                    logging.error(f"   prompt_feedback: {response.prompt_feedback}")

            if task_id:
                update_progress(task_id, "stt", 100, f"ì˜¤ë¥˜: {error_msg}")
            return None, 0.0, "unknown"

        # ì‘ë‹µ íŒŒì‹±
        text = response.text.strip()

        # ë¹ˆ ì‘ë‹µ ì²´í¬
        if not text:
            error_msg = "Gemini APIê°€ ë¹ˆ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤"
            logging.error(f"âŒ {error_msg}")
            logging.error(f"   íŒŒì¼: {audio_path} ({file_size_mb:.2f} MB)")
            if task_id:
                update_progress(task_id, "stt", 100, f"ì˜¤ë¥˜: {error_msg}")
            return None, 0.0, "unknown"

        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
        if text.startswith("```json"):
            text = text[7:]
        elif text.startswith("```"):
            text = text[3:]

        if text.endswith("```"):
            text = text[:-3]

        text = text.strip()

        # ì •ë¦¬ í›„ì—ë„ ë¹ˆ í…ìŠ¤íŠ¸ ì²´í¬
        if not text:
            error_msg = "ì‘ë‹µ ì •ë¦¬ í›„ ë¹ˆ í…ìŠ¤íŠ¸ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤"
            logging.error(f"âŒ {error_msg}")
            logging.error(f"   ì›ë³¸ ì‘ë‹µ ê¸¸ì´: {len(response.text)}")
            if task_id:
                update_progress(task_id, "stt", 100, f"ì˜¤ë¥˜: {error_msg}")
            return None, 0.0, "unknown"

        # ì œì–´ ë¬¸ì ì²˜ë¦¬ (JSON íŒŒì‹± ì—ëŸ¬ ë°©ì§€)
        # JSON ë¬¸ìì—´ ë‚´ì˜ ì œì–´ ë¬¸ìë¥¼ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
        import re

        def escape_control_chars(match):
            """JSON ë¬¸ìì—´ ë‚´ì˜ ì œì–´ ë¬¸ìë¥¼ ì´ìŠ¤ì¼€ì´í”„"""
            char = match.group(0)
            if char == "\n":
                return "\\n"
            elif char == "\r":
                return "\\r"
            elif char == "\t":
                return "\\t"
            elif char == "\b":
                return "\\b"
            elif char == "\f":
                return "\\f"
            else:
                # ê¸°íƒ€ ì œì–´ ë¬¸ìëŠ” ìœ ë‹ˆì½”ë“œ ì´ìŠ¤ì¼€ì´í”„
                return f"\\u{ord(char):04x}"

        # JSON ë¬¸ìì—´ ê°’ ë‚´ë¶€ì˜ ì œì–´ ë¬¸ìë§Œ ì´ìŠ¤ì¼€ì´í”„ (êµ¬ì¡°ëŠ” ìœ ì§€)
        try:
            # "text": "..." íŒ¨í„´ì—ì„œ ë¬¸ìì—´ ê°’ì˜ ì œì–´ ë¬¸ìë§Œ ì²˜ë¦¬
            def fix_text_field(match):
                field_name = match.group(1)
                field_value = match.group(2)
                # ì œì–´ ë¬¸ìë¥¼ ì´ìŠ¤ì¼€ì´í”„
                fixed_value = re.sub(r"[\x00-\x1f]", escape_control_chars, field_value)
                return f'"{field_name}": "{fixed_value}"'

            # "í•„ë“œëª…": "ê°’" í˜•íƒœì˜ ë¬¸ìì—´ í•„ë“œë¥¼ ì°¾ì•„ì„œ ì œì–´ ë¬¸ì ì´ìŠ¤ì¼€ì´í”„
            text = re.sub(
                r'"(text|start_time_mmss)":\s*"([^"]*(?:\\.[^"]*)*)"',
                fix_text_field,
                text,
                flags=re.DOTALL,
            )

        except Exception as e:
            logging.warning(f"âš ï¸ ì œì–´ ë¬¸ì ì´ìŠ¤ì¼€ì´í”„ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")

        # JSON ì‚¬ì „ ì²˜ë¦¬: ê°ì²´ ì‚¬ì´ ëˆ„ë½ëœ ì‰¼í‘œ ì¶”ê°€
        try:
            # } ë‹¤ìŒì— ë°”ë¡œ { ê°€ ì˜¤ëŠ” ê²½ìš° (ì‰¼í‘œ ëˆ„ë½)
            # }\n{ ë˜ëŠ” }\n\n{ ë˜ëŠ” } { íŒ¨í„´ì„ },\n{ ë¡œ ë³€ê²½
            text = re.sub(r"}\s*\n\s*{", "},\n{", text)
            text = re.sub(r"}\s+{", "},\n{", text)
        except Exception as e:
            logging.warning(f"âš ï¸ JSON ì‚¬ì „ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")

        # JSON íŒŒì‹± ì‹œë„
        result = None
        try:
            result = json.loads(text)
        except json.JSONDecodeError as e:
            logging.warning(f"âš ï¸ ì´ˆê¸° JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            logging.warning(f"ì‘ë‹µ ê¸¸ì´: {len(text)} ë¬¸ì")

            # ì—ëŸ¬ ìœ„ì¹˜ ì •ë³´ ì¶œë ¥
            if hasattr(e, "lineno") and hasattr(e, "colno"):
                error_line = (
                    text.split("\n")[e.lineno - 1]
                    if e.lineno <= len(text.split("\n"))
                    else ""
                )
                logging.warning(f"ì—ëŸ¬ ìœ„ì¹˜: line {e.lineno}, column {e.colno}")
                logging.warning(f"ì—ëŸ¬ ë¼ì¸: {error_line[:100]}...")

            # ë³µêµ¬ ì‹œë„ë¥¼ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
            def try_parse_json(json_text):
                """JSON íŒŒì‹± ì‹œë„ (ì œì–´ ë¬¸ì ì²˜ë¦¬ í¬í•¨)"""
                try:
                    return json.loads(json_text)
                except json.JSONDecodeError:
                    # ì œì–´ ë¬¸ì ì²˜ë¦¬ ì¬ì‹œë„
                    try:
                        fixed = re.sub(
                            r'"(text|start_time_mmss)":\s*"([^"]*(?:\\.[^"]*)*)"',
                            fix_text_field,
                            json_text,
                            flags=re.DOTALL,
                        )
                        return json.loads(fixed)
                    except:
                        return None

            # ë³µêµ¬ ì‹œë„ 0: ëˆ„ë½ëœ ì‰¼í‘œ ì¶”ê°€
            if result is None and (
                "Expecting ',' delimiter" in str(e) or "Expecting ','" in str(e)
            ):
                fixed_text = re.sub(r"}\s*\n\s*{", "},\n{", text)
                fixed_text = re.sub(r"}\s+{", "},\n{", fixed_text)
                result = try_parse_json(fixed_text)
                if result:
                    logging.info(
                        f"âœ… JSON ë³µêµ¬ ì„±ê³µ (ì‰¼í‘œ ì¶”ê°€): {len(result)}ê°œ ì„¸ê·¸ë¨¼íŠ¸"
                    )

            # ë³µêµ¬ ì‹œë„ 0.5: Unterminated string ì—ëŸ¬ ì²˜ë¦¬
            if result is None and "Unterminated string" in str(e):
                try:
                    # ì—ëŸ¬ ìœ„ì¹˜(char position)ë¥¼ íŒŒì•…
                    if hasattr(e, "pos"):
                        error_pos = e.pos
                        # ì—ëŸ¬ ìœ„ì¹˜ ì´ì „ì˜ ë§ˆì§€ë§‰ ì™„ì „í•œ ê°ì²´ê¹Œì§€ë§Œ ì‚¬ìš©
                        truncated_text = text[:error_pos]
                        # ë§ˆì§€ë§‰ ì™„ì „í•œ ê°ì²´ë¥¼ ì°¾ê¸°
                        last_complete_brace = truncated_text.rfind("}")
                        if last_complete_brace > 0:
                            fixed_text = (
                                truncated_text[: last_complete_brace + 1] + "\n]"
                            )
                            result = try_parse_json(fixed_text)
                            if result:
                                logging.info(
                                    f"âœ… JSON ë³µêµ¬ ì„±ê³µ (Unterminated string ì²˜ë¦¬): {len(result)}ê°œ ì„¸ê·¸ë¨¼íŠ¸"
                                )
                except Exception:
                    pass

            # ë³µêµ¬ ì‹œë„ 1: ë¶ˆì™„ì „í•œ ë°°ì—´ ë‹«ê¸°
            if result is None and text.startswith("[") and not text.endswith("]"):
                # ë§ˆì§€ë§‰ ì™„ì „í•œ ê°ì²´ë¥¼ ì°¾ê¸° ìœ„í•´ ì—­ìˆœìœ¼ë¡œ ê²€ìƒ‰
                last_complete_brace = text.rfind("}")
                if last_complete_brace > 0:
                    fixed_text = text[: last_complete_brace + 1] + "\n]"
                    result = try_parse_json(fixed_text)
                    if result:
                        logging.info(
                            f"âœ… JSON ë³µêµ¬ ì„±ê³µ (ë¶ˆì™„ì „í•œ ë°°ì—´ ë‹«ê¸°): {len(result)}ê°œ ì„¸ê·¸ë¨¼íŠ¸"
                        )

            # ë³µêµ¬ ì‹œë„ 2: ë§ˆì§€ë§‰ ë¶ˆì™„ì „í•œ í•­ëª© ì œê±°
            if result is None and "," in text:
                # ë§ˆì§€ë§‰ ì½¤ë§ˆ ì´í›„ ë‚´ìš© ì œê±°í•˜ê³  ë°°ì—´ ë‹«ê¸°
                parts = text.rsplit(",", 1)
                if len(parts) == 2:
                    fixed_text = parts[0] + "\n]"
                    result = try_parse_json(fixed_text)
                    if result:
                        logging.info(
                            f"âœ… JSON ë³µêµ¬ ì„±ê³µ (ë§ˆì§€ë§‰ í•­ëª© ì œê±°): {len(result)}ê°œ ì„¸ê·¸ë¨¼íŠ¸"
                        )

            # ë³µêµ¬ ì‹œë„ 3: ë¶ˆì™„ì „í•œ ê°ì²´ ì œê±° í›„ ë°°ì—´ ë‹«ê¸°
            if result is None and text.startswith("["):
                # { ì™€ } ì˜ ê· í˜•ì„ ë§ì¶”ê¸° ìœ„í•´ ë§ˆì§€ë§‰ ì™„ì „í•œ ê°ì²´ ì°¾ê¸°
                depth = 0
                last_valid_pos = -1
                for i, char in enumerate(text):
                    if char == "{":
                        depth += 1
                    elif char == "}":
                        depth -= 1
                        if depth == 0:
                            last_valid_pos = i

                if last_valid_pos > 0:
                    fixed_text = text[: last_valid_pos + 1] + "\n]"
                    result = try_parse_json(fixed_text)
                    if result:
                        logging.info(
                            f"âœ… JSON ë³µêµ¬ ì„±ê³µ (ê¹Šì´ ë¶„ì„): {len(result)}ê°œ ì„¸ê·¸ë¨¼íŠ¸"
                        )

            # ë³µêµ¬ ì‹œë„ 4: ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ìœ íš¨í•œ JSON ê°ì²´ë§Œ ì¶”ì¶œ
            if result is None:
                try:
                    lines = text.split("\n")
                    recovered_items = []
                    current_obj = ""
                    depth = 0

                    for line in lines:
                        current_obj += line
                        for char in line:
                            if char == "{":
                                depth += 1
                            elif char == "}":
                                depth -= 1

                        if depth == 0 and current_obj.strip():
                            # ì™„ì „í•œ ê°ì²´ì¼ ìˆ˜ ìˆìŒ
                            obj_text = current_obj.strip().rstrip(",")
                            obj = try_parse_json(obj_text)
                            if obj and isinstance(obj, dict):
                                recovered_items.append(obj)
                            current_obj = ""

                    if recovered_items:
                        result = recovered_items
                        logging.info(
                            f"âœ… JSON ë³µêµ¬ ì„±ê³µ (ë¼ì¸ ë¶„ì„): {len(result)}ê°œ ì„¸ê·¸ë¨¼íŠ¸"
                        )
                except Exception:
                    pass

            # ëª¨ë“  ë³µêµ¬ ì‹œë„ ì‹¤íŒ¨
            if result is None:
                logging.error(f"âŒ JSON ë³µêµ¬ ì‹¤íŒ¨")
                logging.error(f"ì‘ë‹µ í…ìŠ¤íŠ¸ (ì²˜ìŒ 500ì): {text[:500]}")
                logging.error(f"ì‘ë‹µ í…ìŠ¤íŠ¸ (ë§ˆì§€ë§‰ 500ì): {text[-500:]}")
                if task_id:
                    update_progress(task_id, "stt", 100, f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
                return None, 0.0, "unknown"
            else:
                # ë³µêµ¬ ì„±ê³µ - ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                if task_id:
                    update_progress(
                        task_id,
                        "stt",
                        60,
                        f"JSON ë³µêµ¬ ì™„ë£Œ, {len(result)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ íŒŒì‹± ì¤‘...",
                    )

        # ì„¸ê·¸ë¨¼íŠ¸ ë³€í™˜
        segments = []
        for idx, item in enumerate(result):
            start_time_str = item.get("start_time_mmss", "0:00:000")
            segment_start = parse_mmss_to_seconds(start_time_str)

            # end_time ê³„ì‚°: ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ì˜ start_time ë˜ëŠ” audio_duration
            end_time = None
            if idx < len(result) - 1:
                # ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ê°€ ìˆìœ¼ë©´ ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ì˜ start_time ì‚¬ìš©
                next_start_time_str = result[idx + 1].get("start_time_mmss", "0:00:000")
                end_time = parse_mmss_to_seconds(next_start_time_str)
            elif audio_duration is not None:
                # ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ë©´ ì˜¤ë””ì˜¤ ì´ ê¸¸ì´ ì‚¬ìš©
                end_time = audio_duration

            segments.append(
                {
                    "id": idx + 1,
                    "speaker": str(item.get("speaker", "Unknown")),
                    "start_time": segment_start,
                    "end_time": end_time,
                    "confidence": float(item.get("confidence", 0.0)),
                    "text": item.get("text", ""),
                }
            )

        # ê¸´ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í•  (5ê°œ ì´ìƒì˜ ë¬¸ì¥ì¸ ê²½ìš°)
        if task_id:
            update_progress(task_id, "stt", 70, "ê¸´ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í•  ì²˜ë¦¬ ì¤‘...")

        def split_long_segment(segment):
            """5ê°œ ì´ìƒì˜ ë¬¸ì¥ì„ ê°€ì§„ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ë¶„í• """
            text = segment["text"]

            # ë¬¸ì¥ êµ¬ë¶„ìë¡œ ë¶„ë¦¬ (í•œêµ­ì–´ì™€ ì˜ì–´ ëª¨ë‘ ì§€ì›)
            import re

            # ë¬¸ì¥ ë íŒ¨í„´: . ! ? ë’¤ì— ê³µë°±ì´ë‚˜ ì¤„ë°”ê¿ˆ
            sentences = re.split(r"([.!?]+[\s\n]+)", text)

            # êµ¬ë¶„ìë¥¼ ë¬¸ì¥ì— ë‹¤ì‹œ ë¶™ì´ê¸°
            full_sentences = []
            for i in range(0, len(sentences) - 1, 2):
                if i + 1 < len(sentences):
                    full_sentences.append(sentences[i] + sentences[i + 1])
                else:
                    full_sentences.append(sentences[i])

            # ë§ˆì§€ë§‰ ìš”ì†Œê°€ êµ¬ë¶„ìê°€ ì•„ë‹Œ ê²½ìš° ì¶”ê°€
            if len(sentences) % 2 == 1:
                full_sentences.append(sentences[-1])

            # ë¹ˆ ë¬¸ì¥ ì œê±°
            full_sentences = [s.strip() for s in full_sentences if s.strip()]

            # 5ê°œ ë¯¸ë§Œì´ë©´ ë¶„í• í•˜ì§€ ì•ŠìŒ
            if len(full_sentences) < 5:
                return [segment]

            # ì„¸ê·¸ë¨¼íŠ¸ ë¶„í•  (4ê°œ ë¬¸ì¥ì”©)
            split_segments = []
            chunk_size = 4
            total_duration = (segment["end_time"] or segment["start_time"]) - segment[
                "start_time"
            ]

            for i in range(0, len(full_sentences), chunk_size):
                chunk_sentences = full_sentences[i : i + chunk_size]
                chunk_text = " ".join(chunk_sentences)

                # ì‹œê°„ ë¹„ìœ¨ë¡œ ê³„ì‚°
                sentence_ratio = len(chunk_sentences) / len(full_sentences)
                chunk_start = segment["start_time"] + (
                    total_duration * (i / len(full_sentences))
                )
                chunk_end = segment["start_time"] + (
                    total_duration * ((i + len(chunk_sentences)) / len(full_sentences))
                )

                split_segments.append(
                    {
                        "id": segment["id"],  # IDëŠ” ë‚˜ì¤‘ì— ì¬í• ë‹¹
                        "speaker": segment["speaker"],
                        "start_time": chunk_start,
                        "end_time": chunk_end,
                        "confidence": segment["confidence"],
                        "text": chunk_text,
                    }
                )

            return split_segments

        # ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•´ ë¶„í•  ì ìš©
        original_count = len(segments)
        split_segments = []
        for seg in segments:
            split_segments.extend(split_long_segment(seg))

        # ID ì¬í• ë‹¹
        for idx, seg in enumerate(split_segments, 1):
            seg["id"] = idx

        segments = split_segments

        if len(segments) > original_count:
            logging.info(f"ğŸ“ ê¸´ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í• : {original_count}ê°œ â†’ {len(segments)}ê°œ")

        # ì–¸ì–´ ê°ì§€ (ì²« ë²ˆì§¸ ì„¸ê·¸ë¨¼íŠ¸ í…ìŠ¤íŠ¸ ì‚¬ìš©)
        detected_language = "unknown"
        if segments and len(segments) > 0:
            first_text = segments[0].get("text", "")
            if first_text and first_text.strip():
                try:
                    if task_id:
                        update_progress(task_id, "stt", 80, "ì–¸ì–´ ê°ì§€ ì¤‘...")

                    from modules.translation import detect_language

                    detected_language = detect_language(first_text)
                    logging.info(f"ğŸŒ ê°ì§€ëœ ì–¸ì–´: {detected_language}")
                except Exception as e:
                    logging.warning(f"âš ï¸ ì–¸ì–´ ê°ì§€ ì‹¤íŒ¨, ê¸°ë³¸ê°’(unknown) ì‚¬ìš©: {e}")
                    detected_language = "unknown"

        processing_time = time.time() - start_time
        logging.info(
            f"âœ… Gemini STT ì™„ë£Œ: {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸, ì–¸ì–´: {detected_language} ({processing_time:.2f}ì´ˆ)"
        )

        if task_id:
            update_progress(
                task_id, "stt", 100, f"STT ì™„ë£Œ: {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸"
            )

        return segments, processing_time, detected_language

    except Exception as e:
        error_type = type(e).__name__
        error_msg = str(e)

        logging.error(f"âŒ Gemini STT ì˜¤ë¥˜ ë°œìƒ")
        logging.error(f"   ì˜¤ë¥˜ íƒ€ì…: {error_type}")
        logging.error(f"   ì˜¤ë¥˜ ë©”ì‹œì§€: {error_msg}")
        logging.error(f"   íŒŒì¼ ê²½ë¡œ: {audio_path}")

        # íŒŒì¼ ì •ë³´ ì¶œë ¥ (íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°)
        try:
            if os.path.exists(audio_path):
                file_size = os.path.getsize(audio_path)
                file_size_mb = file_size / (1024 * 1024)
                file_ext = os.path.splitext(audio_path)[1].lower()
                logging.error(f"   íŒŒì¼ í¬ê¸°: {file_size_mb:.2f} MB")
                logging.error(f"   íŒŒì¼ í™•ì¥ì: {file_ext}")
            else:
                logging.error(f"   íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
        except:
            pass

        import traceback

        logging.error("   ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:")
        traceback.print_exc()

        if task_id:
            update_progress(
                task_id, "stt", 100, f"ì˜¤ë¥˜ [{error_type}]: {error_msg[:100]}"
            )

        return None, 0.0, "unknown"


def split_audio_with_overlap(
    audio_path, chunk_duration_minutes=30, overlap_seconds=25
):
    """
    ê¸´ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì¤‘ë³µ êµ¬ê°„ê³¼ í•¨ê»˜ ë¶„í• 

    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        chunk_duration_minutes: ê° ì²­í¬ì˜ ê¸¸ì´ (ë¶„)
        overlap_seconds: ì²­í¬ ê°„ ì¤‘ë³µ êµ¬ê°„ (ì´ˆ)

    Returns:
        list: [(chunk_file_path, start_offset_seconds, end_offset_seconds), ...]
    """
    logging.info(f"ğŸ”ª ì˜¤ë””ì˜¤ ë¶„í•  ì‹œì‘: {audio_path}")

    try:
        # ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ
        audio = AudioSegment.from_file(audio_path)
        total_duration_ms = len(audio)
        total_duration_sec = total_duration_ms / 1000.0

        logging.info(f"ğŸ“ ì´ ì˜¤ë””ì˜¤ ê¸¸ì´: {total_duration_sec:.2f}ì´ˆ ({total_duration_sec/60:.2f}ë¶„)")

        # ë¶„í• ì´ í•„ìš”í•œì§€ í™•ì¸
        chunk_duration_ms = chunk_duration_minutes * 60 * 1000
        if total_duration_ms <= chunk_duration_ms:
            logging.info("â­ï¸  ë¶„í• ì´ í•„ìš” ì—†ëŠ” ê¸¸ì´ì…ë‹ˆë‹¤.")
            return [(audio_path, 0, total_duration_sec)]

        # ë¶„í•  ìˆ˜í–‰
        overlap_ms = overlap_seconds * 1000
        chunks = []
        start_ms = 0
        chunk_index = 0

        while start_ms < total_duration_ms:
            # ì²­í¬ ì¢…ë£Œ ì‹œì  ê³„ì‚°
            end_ms = min(start_ms + chunk_duration_ms, total_duration_ms)

            # ì²­í¬ ì¶”ì¶œ
            chunk = audio[start_ms:end_ms]

            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            chunk_file = tempfile.NamedTemporaryFile(
                suffix=os.path.splitext(audio_path)[1],
                delete=False
            )
            chunk_file_path = chunk_file.name
            chunk_file.close()

            chunk.export(chunk_file_path, format=os.path.splitext(audio_path)[1][1:])

            start_sec = start_ms / 1000.0
            end_sec = end_ms / 1000.0

            chunks.append((chunk_file_path, start_sec, end_sec))

            logging.info(
                f"ğŸ“¦ ì²­í¬ {chunk_index + 1} ìƒì„±: "
                f"{start_sec:.2f}s ~ {end_sec:.2f}s "
                f"(ê¸¸ì´: {(end_sec - start_sec) / 60:.2f}ë¶„)"
            )

            # ë‹¤ìŒ ì²­í¬ ì‹œì‘ ì§€ì  (ì¤‘ë³µ êµ¬ê°„ ê³ ë ¤)
            start_ms = end_ms - overlap_ms
            chunk_index += 1

            # ë§ˆì§€ë§‰ ì²­í¬ë©´ ì¢…ë£Œ
            if end_ms >= total_duration_ms:
                break

        logging.info(f"âœ… ì˜¤ë””ì˜¤ ë¶„í•  ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬")
        return chunks

    except Exception as e:
        logging.error(f"âŒ ì˜¤ë””ì˜¤ ë¶„í•  ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return [(audio_path, 0, None)]


def find_best_overlap_match(text1, text2, min_match_length=10):
    """
    ë‘ í…ìŠ¤íŠ¸ì—ì„œ ì¤‘ë³µë˜ëŠ” ê°€ì¥ ê¸´ ë¶€ë¶„ì„ ì°¾ìŒ

    Args:
        text1: ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ (ì´ì „ ì²­í¬ì˜ ëë¶€ë¶„)
        text2: ë‘ ë²ˆì§¸ í…ìŠ¤íŠ¸ (ë‹¤ìŒ ì²­í¬ì˜ ì‹œì‘ë¶€ë¶„)
        min_match_length: ìµœì†Œ ë§¤ì¹­ ê¸¸ì´ (ë¬¸ì ìˆ˜)

    Returns:
        tuple: (text1ì—ì„œì˜ ë§¤ì¹­ ì‹œì‘ ìœ„ì¹˜, text2ì—ì„œì˜ ë§¤ì¹­ ì¢…ë£Œ ìœ„ì¹˜)
    """
    # í…ìŠ¤íŠ¸ë¥¼ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¶„í• 
    words1 = text1.split()
    words2 = text2.split()

    # ìµœì†Œ ë‹¨ì–´ ìˆ˜
    min_words = max(3, min_match_length // 5)

    best_match = None
    best_ratio = 0.0

    # text1ì˜ ëë¶€ë¶„ì—ì„œ ê°€ëŠ¥í•œ ì‹œì‘ì ë“¤ì„ íƒìƒ‰
    search_start = max(0, len(words1) - 100)  # ë’¤ìª½ 100ë‹¨ì–´ë§Œ íƒìƒ‰

    for i in range(search_start, len(words1)):
        # text2ì˜ ì•ë¶€ë¶„ì—ì„œ ë§¤ì¹­ ì‹œë„
        for j in range(min(len(words2), 100)):  # ì•ìª½ 100ë‹¨ì–´ë§Œ íƒìƒ‰
            # ê°€ëŠ¥í•œ ë§¤ì¹­ ê¸¸ì´ë“¤ì„ ì‹œë„
            for length in range(
                min_words,
                min(len(words1) - i, len(words2) - j) + 1
            ):
                seq1 = " ".join(words1[i : i + length])
                seq2 = " ".join(words2[j : j + length])

                # ìœ ì‚¬ë„ ê³„ì‚°
                ratio = SequenceMatcher(None, seq1, seq2).ratio()

                if ratio > best_ratio and ratio > 0.8:  # 80% ì´ìƒ ìœ ì‚¬
                    best_ratio = ratio
                    best_match = (i, j + length, length, ratio)

    if best_match:
        i, j, length, ratio = best_match
        logging.info(
            f"ğŸ”— ì¤‘ë³µ êµ¬ê°„ ë°œê²¬: "
            f"{length}ë‹¨ì–´ ë§¤ì¹­ (ìœ ì‚¬ë„: {ratio:.2%})"
        )
        # text1ì—ì„œ ë§¤ì¹­ ì‹œì‘ ìœ„ì¹˜, text2ì—ì„œ ë§¤ì¹­ ì¢…ë£Œ ìœ„ì¹˜ ë°˜í™˜
        return (i, j)

    logging.warning("âš ï¸  ì¤‘ë³µ êµ¬ê°„ì„ ì°¾ì§€ ëª»í•¨, ë‹¨ìˆœ ì—°ê²°")
    return (len(words1), 0)


def merge_segment_lists(segments_list, chunk_info_list, overlap_seconds=25):
    """
    ì—¬ëŸ¬ ì²­í¬ì˜ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë³‘í•©

    Args:
        segments_list: ê° ì²­í¬ì˜ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸ [segments1, segments2, ...]
        chunk_info_list: ê° ì²­í¬ì˜ ì •ë³´ [(start_offset, end_offset), ...]
        overlap_seconds: ì¤‘ë³µ êµ¬ê°„ ê¸¸ì´ (ì´ˆ)

    Returns:
        list: ë³‘í•©ëœ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
    """
    if not segments_list or len(segments_list) == 0:
        return []

    if len(segments_list) == 1:
        return segments_list[0]

    logging.info(f"ğŸ”— ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ì‹œì‘: {len(segments_list)}ê°œ ì²­í¬")

    merged = []

    for chunk_idx, (segments, chunk_info) in enumerate(zip(segments_list, chunk_info_list)):
        start_offset, end_offset = chunk_info

        if chunk_idx == 0:
            # ì²« ë²ˆì§¸ ì²­í¬ëŠ” ì „ì²´ ì¶”ê°€
            merged.extend(segments)
            logging.info(f"âœ… ì²­í¬ 0: {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€")
        else:
            # ì´ì „ ì²­í¬ì˜ ëë¶€ë¶„ê³¼ í˜„ì¬ ì²­í¬ì˜ ì‹œì‘ë¶€ë¶„ì—ì„œ ì¤‘ë³µ ì°¾ê¸°
            prev_chunk_start_offset = chunk_info_list[chunk_idx - 1][0]

            # ì´ì „ ì²­í¬ì˜ ë§ˆì§€ë§‰ Nê°œ ì„¸ê·¸ë¨¼íŠ¸ í…ìŠ¤íŠ¸
            prev_segments = segments_list[chunk_idx - 1]
            prev_text = " ".join([s.get("text", "") for s in prev_segments[-20:]])

            # í˜„ì¬ ì²­í¬ì˜ ì²˜ìŒ Nê°œ ì„¸ê·¸ë¨¼íŠ¸ í…ìŠ¤íŠ¸
            curr_text = " ".join([s.get("text", "") for s in segments[:20]])

            # ì¤‘ë³µ êµ¬ê°„ ì°¾ê¸°
            if prev_text and curr_text:
                prev_word_idx, curr_word_idx = find_best_overlap_match(prev_text, curr_text)

                # ì¤‘ë³µì„ ê¸°ì¤€ìœ¼ë¡œ í˜„ì¬ ì²­í¬ì—ì„œ ì¶”ê°€í•  ë¶€ë¶„ ê²°ì •
                # í˜„ì¬ ì²­í¬ì˜ ì„¸ê·¸ë¨¼íŠ¸ ì¤‘ ì¤‘ë³µ ì´í›„ ë¶€ë¶„ë§Œ ì¶”ê°€

                # í˜„ì¬ ì²­í¬ ì„¸ê·¸ë¨¼íŠ¸ì˜ í…ìŠ¤íŠ¸ë¥¼ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ê³„ì‚°
                word_count = 0
                skip_until_idx = 0

                for idx, seg in enumerate(segments):
                    seg_words = len(seg.get("text", "").split())
                    word_count += seg_words
                    if word_count >= curr_word_idx:
                        skip_until_idx = idx + 1
                        break

                segments_to_add = segments[skip_until_idx:]
                logging.info(
                    f"âœ… ì²­í¬ {chunk_idx}: "
                    f"{len(segments_to_add)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€ "
                    f"(ì²˜ìŒ {skip_until_idx}ê°œ ì¤‘ë³µ ì œê±°)"
                )
            else:
                # ì¤‘ë³µì„ ì°¾ì§€ ëª»í•œ ê²½ìš°, ë‹¨ìˆœíˆ ì¤‘ë³µ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì œê±°
                segments_to_add = [
                    s for s in segments
                    if s.get("start_time", 0) >= overlap_seconds
                ]
                logging.warning(
                    f"âš ï¸  ì²­í¬ {chunk_idx}: í…ìŠ¤íŠ¸ ë§¤ì¹­ ì‹¤íŒ¨, "
                    f"ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ {len(segments_to_add)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€"
                )

            # ì‹œê°„ ì˜¤í”„ì…‹ ì¡°ì •
            for seg in segments_to_add:
                if "start_time" in seg and seg["start_time"] is not None:
                    seg["start_time"] += start_offset
                if "end_time" in seg and seg["end_time"] is not None:
                    seg["end_time"] += start_offset

            merged.extend(segments_to_add)

    # ID ì¬í• ë‹¹
    for idx, seg in enumerate(merged, 1):
        seg["id"] = idx

    logging.info(f"âœ… ë³‘í•© ì™„ë£Œ: ì´ {len(merged)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
    return merged


def recognize_with_gemini_chunked(
    audio_path,
    task_id=None,
    audio_duration=None,
    chunk_duration_minutes=30,
    overlap_seconds=25
):
    """
    ê¸´ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬ í›„ ë³‘í•©

    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        task_id: ì§„í–‰ ìƒí™© ì¶”ì ìš© ID
        audio_duration: ì˜¤ë””ì˜¤ ì´ ê¸¸ì´ (ì´ˆ)
        chunk_duration_minutes: ê° ì²­í¬ ê¸¸ì´ (ë¶„)
        overlap_seconds: ì²­í¬ ê°„ ì¤‘ë³µ ì‹œê°„ (ì´ˆ)

    Returns:
        tuple: (segments, processing_time, detected_language)
    """
    from modules.utils import update_progress

    overall_start_time = time.time()

    try:
        if task_id:
            update_progress(task_id, "stt", 0, "ì˜¤ë””ì˜¤ ë¶„í•  ì¤‘...")

        # ì˜¤ë””ì˜¤ ë¶„í• 
        chunk_info_list = split_audio_with_overlap(
            audio_path,
            chunk_duration_minutes=chunk_duration_minutes,
            overlap_seconds=overlap_seconds
        )

        if len(chunk_info_list) == 1 and chunk_info_list[0][0] == audio_path:
            # ë¶„í• ì´ í•„ìš” ì—†ëŠ” ê²½ìš° ê¸°ì¡´ í•¨ìˆ˜ ì‚¬ìš©
            logging.info("â­ï¸  ì²­í¬ ì²˜ë¦¬ ë¶ˆí•„ìš”, ì¼ë°˜ ì²˜ë¦¬ë¡œ ì „í™˜")
            return recognize_with_gemini(audio_path, task_id, audio_duration)

        # ê° ì²­í¬ ì²˜ë¦¬
        all_segments = []
        detected_languages = []
        temp_files = []

        for chunk_idx, (chunk_path, start_offset, end_offset) in enumerate(chunk_info_list):
            if task_id:
                progress = int((chunk_idx / len(chunk_info_list)) * 90)
                update_progress(
                    task_id,
                    "stt",
                    progress,
                    f"ì²­í¬ {chunk_idx + 1}/{len(chunk_info_list)} ì²˜ë¦¬ ì¤‘..."
                )

            logging.info(
                f"ğŸ¯ ì²­í¬ {chunk_idx + 1}/{len(chunk_info_list)} ì²˜ë¦¬: "
                f"{start_offset:.2f}s ~ {end_offset:.2f}s"
            )

            # ì²­í¬ì˜ ê¸¸ì´ ê³„ì‚°
            chunk_duration = end_offset - start_offset

            # STT ìˆ˜í–‰
            segments, proc_time, lang = recognize_with_gemini(
                chunk_path,
                task_id=None,  # ê°œë³„ ì²­í¬ëŠ” ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ ì•ˆí•¨
                audio_duration=chunk_duration
            )

            if segments:
                all_segments.append(segments)
                detected_languages.append(lang)

                # ì„ì‹œ íŒŒì¼ ê¸°ë¡ (ë‚˜ì¤‘ì— ì‚­ì œ)
                if chunk_path != audio_path:
                    temp_files.append(chunk_path)
            else:
                logging.error(f"âŒ ì²­í¬ {chunk_idx + 1} ì²˜ë¦¬ ì‹¤íŒ¨")

        # ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•©
        if task_id:
            update_progress(task_id, "stt", 95, "ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ì¤‘...")

        merged_segments = merge_segment_lists(
            all_segments,
            [(start, end) for _, start, end in chunk_info_list],
            overlap_seconds=overlap_seconds
        )

        # ì–¸ì–´ ê²°ì • (ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ì–¸ì–´)
        if detected_languages:
            from collections import Counter
            detected_language = Counter(detected_languages).most_common(1)[0][0]
        else:
            detected_language = "unknown"

        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        for temp_file in temp_files:
            try:
                if os.path.exists(temp_file):
                    os.remove(temp_file)
                    logging.debug(f"ğŸ—‘ï¸  ì„ì‹œ íŒŒì¼ ì‚­ì œ: {temp_file}")
            except Exception as e:
                logging.warning(f"âš ï¸  ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {temp_file}, {e}")

        processing_time = time.time() - overall_start_time

        logging.info(
            f"âœ… ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ: {len(merged_segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸, "
            f"ì–¸ì–´: {detected_language} ({processing_time:.2f}ì´ˆ)"
        )

        if task_id:
            update_progress(
                task_id,
                "stt",
                100,
                f"STT ì™„ë£Œ: {len(merged_segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸"
            )

        return merged_segments, processing_time, detected_language

    except Exception as e:
        logging.error(f"âŒ ì²­í¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

        # ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ fallback
        logging.info("ğŸ”„ ì¼ë°˜ ì²˜ë¦¬ë¡œ fallback")
        return recognize_with_gemini(audio_path, task_id, audio_duration)
