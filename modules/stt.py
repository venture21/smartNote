"""
STT (Speech-to-Text) ëª¨ë“ˆ - Gemini API ì‚¬ìš©
Google AI Studio ë° Vertex AI ì§€ì›
"""

import os
import logging
import time
import json
import tempfile
from difflib import SequenceMatcher
from pydub import AudioSegment
from google import genai
from google.genai import types


def get_gemini_client(api_type="google_ai_studio"):
    """
    Gemini í´ë¼ì´ì–¸íŠ¸ ìƒì„±

    Args:
        api_type: "google_ai_studio" ë˜ëŠ” "vertex_ai"

    Returns:
        í´ë¼ì´ì–¸íŠ¸ ê°ì²´
    """
    if api_type == "vertex_ai":
        # Vertex AI í´ë¼ì´ì–¸íŠ¸
        import vertexai
        from vertexai.generative_models import GenerativeModel

        project_id = os.environ.get("VERTEX_AI_PROJECT_ID")
        location = os.environ.get("VERTEX_AI_LOCATION", "us-central1")

        if not project_id:
            error_msg = (
                "âŒ Vertex AI ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.\n\n"
                "í•´ê²° ë°©ë²•:\n"
                "1. .env íŒŒì¼ì— ë‹¤ìŒì„ ì¶”ê°€í•˜ì„¸ìš”:\n"
                "   VERTEX_AI_PROJECT_ID=your-gcp-project-id\n\n"
                "2. ë˜ëŠ” Google AI Studioë¥¼ ì‚¬ìš©í•˜ì„¸ìš” (ë¬´ë£Œ):\n"
                "   ì›¹ UIì—ì„œ 'Google AI Studio'ë¥¼ ì„ íƒí•˜ì„¸ìš”.\n\n"
                "ìì„¸í•œ ë‚´ìš©ì€ STT_API_GUIDE.mdë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."
            )
            logging.error(error_msg)
            raise ValueError(
                "Vertex AIë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ VERTEX_AI_PROJECT_ID í™˜ê²½ ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤. "
                ".env íŒŒì¼ì— ì„¤ì •í•˜ê±°ë‚˜ Google AI Studioë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
            )

        try:
            vertexai.init(project=project_id, location=location)
            logging.info(f"âœ… Vertex AI ì´ˆê¸°í™” ì™„ë£Œ: {project_id}, {location}")
        except Exception as e:
            error_msg = (
                f"âŒ Vertex AI ì¸ì¦ ì‹¤íŒ¨: {e}\n\n"
                "í•´ê²° ë°©ë²•:\n"
                "1. ì¸ì¦ ì„¤ì •: gcloud auth application-default login\n"
                "2. ë˜ëŠ” ì„œë¹„ìŠ¤ ê³„ì • í‚¤ ì„¤ì •:\n"
                "   GOOGLE_APPLICATION_CREDENTIALS=/path/to/key.json\n\n"
                "ìì„¸í•œ ë‚´ìš©ì€ STT_API_GUIDE.mdë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."
            )
            logging.error(error_msg)
            raise ValueError(
                f"Vertex AI ì¸ì¦ ì‹¤íŒ¨: {e}. "
                "gcloud authë¥¼ ì‹¤í–‰í•˜ê±°ë‚˜ Google AI Studioë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
            )

        # Vertex AI ëª¨ë¸ ì„¤ì •
        # Google AI Studioì™€ ë™ì¼í•˜ê²Œ gemini-2.5-pro ì‚¬ìš© ì‹œë„
        #
        # âš ï¸ ì£¼ì˜: gemini-2.5-proëŠ” ì¼ë¶€ Vertex AI ë¦¬ì „ì—ì„œ ì‚¬ìš© ë¶ˆê°€í•  ìˆ˜ ìˆìŒ
        # ì‚¬ìš© ë¶ˆê°€ ì‹œ ìë™ìœ¼ë¡œ gemini-2.5-flashë¡œ fallback
        #
        # íƒ€ì„ìŠ¤íƒ¬í”„ ì •í™•ë„ ë¹„êµ:
        # - gemini-2.5-pro: âœ…âœ… ìµœê³  (Google AI Studioì™€ ë™ì¼)
        # - gemini-2.5-flash: âœ…âœ… ë§¤ìš° ë†’ìŒ (ë¹ ë¥´ê³  ì •í™•)
        # - gemini-1.5-pro: âœ… ë†’ìŒ
        # - gemini-1.5-flash-002: âš ï¸ ë³´í†µ
        # - gemini-2.0-flash-exp: âŒ ë‚®ìŒ (ì‚¬ìš© ê¸ˆì§€)

        model_name = os.environ.get("VERTEX_AI_MODEL", "gemini-2.5-pro")
        logging.info(f"ğŸ¤– Vertex AI ëª¨ë¸ ì‹œë„: {model_name}")
        logging.info(f"   í”„ë¡œì íŠ¸: {project_id}, ë¦¬ì „: {location}")

        try:
            model = GenerativeModel(model_name)
            logging.info(f"âœ… {model_name} ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
            if "2.5" in model_name:
                logging.info(f"ğŸ‰ ìµœì‹  Gemini 2.5 ëª¨ë¸ ì‚¬ìš© ì¤‘!")
            return model
        except Exception as e:
            # Fallback: gemini-2.5-proê°€ ì•ˆ ë˜ë©´ gemini-2.5-flash ì‹œë„
            if "2.5-pro" in model_name:
                logging.warning(
                    f"âš ï¸ {model_name}ëŠ” ì´ ë¦¬ì „ì—ì„œ ì‚¬ìš© ë¶ˆê°€, gemini-2.5-flashë¡œ ì „í™˜"
                )
                logging.warning(f"   ì˜¤ë¥˜: {e}")
                model_name = "gemini-2.5-flash"
                try:
                    model = GenerativeModel(model_name)
                    logging.info(f"âœ… Fallback ëª¨ë¸ ë¡œë“œ: {model_name} (ë¹ ë¥´ê³  ì •í™•)")
                    return model
                except Exception as e2:
                    # 2ì°¨ fallback: gemini-2.5-flashë„ ì•ˆ ë˜ë©´ gemini-1.5-pro
                    logging.warning(f"âš ï¸ {model_name}ë„ ì‹¤íŒ¨, gemini-1.5-proë¡œ ì „í™˜")
                    model_name = "gemini-1.5-pro"
                    model = GenerativeModel(model_name)
                    logging.info(f"âœ… ìµœì¢… Fallback ëª¨ë¸ ë¡œë“œ: {model_name}")
                    return model
            else:
                # ë‹¤ë¥¸ ëª¨ë¸ ì‹¤íŒ¨ ì‹œ
                logging.warning(f"âš ï¸ {model_name} ì‚¬ìš© ë¶ˆê°€, gemini-1.5-proë¡œ ì „í™˜: {e}")
                model_name = "gemini-1.5-pro"
                model = GenerativeModel(model_name)
                logging.info(f"âœ… Fallback ëª¨ë¸ ë¡œë“œ: {model_name}")
                return model
    else:
        # Google AI Studio í´ë¼ì´ì–¸íŠ¸
        api_key = os.environ.get("GOOGLE_API_KEY")
        if api_key:
            return genai.Client(api_key=api_key)
        else:
            return genai.Client()


def get_stt_prompt(api_type="google_ai_studio"):
    """
    STT API íƒ€ì…ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ìƒì„±

    Args:
        api_type: "google_ai_studio" ë˜ëŠ” "vertex_ai"

    Returns:
        str: STT í”„ë¡¬í”„íŠ¸
    """
    if api_type == "vertex_ai":
        # Vertex AI ì „ìš© í”„ë¡¬í”„íŠ¸ (ì•ˆì •í™” ë²„ì „ì— ìµœì í™”)
        return """
ë‹¹ì‹ ì€ ì˜¤ë””ì˜¤ íƒ€ì„ìŠ¤íƒ¬í”„ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

âš ï¸ ì¤‘ìš” ë¬¸ì œ ì¸ì‹:
í˜„ì¬ Vertex AI ì•ˆì •í™” ëª¨ë¸ì€ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì¶”ì •í•˜ëŠ” ê²½í–¥ì´ ìˆì–´ ì‹¤ì œ ì‹œê°„ê³¼ 10-50ì´ˆ ì°¨ì´ê°€ ë°œìƒí•©ë‹ˆë‹¤.
ì´ëŠ” ì ˆëŒ€ í—ˆìš©ë  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°˜ë“œì‹œ ì˜¤ë””ì˜¤ì˜ ì‹¤ì œ ì¬ìƒ ì‹œê°„ì„ ì •í™•íˆ ì½ì–´ì•¼ í•©ë‹ˆë‹¤.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ì‘ì—… ìš°ì„ ìˆœìœ„ (ìˆ«ìê°€ ì‘ì„ìˆ˜ë¡ ì¤‘ìš”):
1ìˆœìœ„: start_time ì •í™•ë„ (ìµœìš°ì„ , ì ˆëŒ€ì )
2ìˆœìœ„: í…ìŠ¤íŠ¸ ì •í™•ë„
3ìˆœìœ„: confidence ì •í™•ë„
4ìˆœìœ„: speaker êµ¬ë¶„ (ëŒ€ëµì ìœ¼ë¡œë§Œ ê°€ëŠ¥)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ã€1ìˆœìœ„ í•„ìˆ˜ã€‘start_time ì •í™•ë„ ìš”êµ¬ì‚¬í•­:

Step 1: ì •í™•í•œ ë°œí™” ì‹œì‘ ì‹œì  íŒŒì•…
- ê° ë°œí™”ê°€ **ì‹¤ì œë¡œ ì‹œì‘ë˜ëŠ” ì •í™•í•œ ìˆœê°„**ì„ ì°¾ìœ¼ì„¸ìš”
- ë°œí™” ì‹œì‘ = ì²« ìŒì ˆì´ ë“¤ë¦¬ê¸° ì‹œì‘í•˜ëŠ” ìˆœê°„
- ë„ˆë¬´ ì¼ì° í‘œì‹œí•˜ì§€ ë§ˆì„¸ìš” (ë°œí™” ì „ ì¹¨ë¬µì„ ì‹œì‘ì ìœ¼ë¡œ ì°©ê° ê¸ˆì§€)
- ë„ˆë¬´ ëŠ¦ê²Œ í‘œì‹œí•˜ì§€ ë§ˆì„¸ìš” (ë°œí™” ì¤‘ê°„ì„ ì‹œì‘ì ìœ¼ë¡œ ì°©ê° ê¸ˆì§€)

ì˜ˆì‹œ:
âœ… ì˜¬ë°”ë¥¸ ì˜ˆ: 0:01:14.50ì— "ì§€ê¸ˆ ì´ì œ" ìŒì„±ì´ ì‹¤ì œë¡œ ì‹œì‘ â†’ start_time: "0:01:14.50"
âŒ ì˜ëª»ëœ ì˜ˆ (ë„ˆë¬´ ë¹ ë¦„): 0:01:14.50ì— ì‹œì‘í•˜ëŠ”ë° â†’ start_time: "0:01:10.00" (4.5ì´ˆ ë¹ ë¦„)
âŒ ì˜ëª»ëœ ì˜ˆ (ë„ˆë¬´ ëŠë¦¼): 0:01:14.50ì— ì‹œì‘í•˜ëŠ”ë° â†’ start_time: "0:01:18.00" (3.5ì´ˆ ëŠë¦¼)

Step 2: ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œê°„ ì •í™•íˆ ì½ê¸°
- ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ì˜ í˜„ì¬ ì¬ìƒ ì‹œê°„ì„ ì •í™•íˆ í™•ì¸
- ë°œí™”ê°€ ì‹œì‘ë˜ëŠ” ìˆœê°„ì˜ í”Œë ˆì´ì–´ ì‹œê°„ = start_time
- ì ˆëŒ€ë¡œ ì¶”ì •, ê³„ì‚°, ê·¼ì‚¬ì¹˜ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”

Step 3: í˜•ì‹ ì¤€ìˆ˜
- "ì‹œ:ë¶„:ì´ˆ.ë°±ë¶„ì˜1ì´ˆ" í˜•ì‹ ì‚¬ìš©
- ì˜ˆì‹œ: "0:00:05.23", "0:01:14.56", "1:02:30.78"
- ë°±ë¶„ì˜1ì´ˆê¹Œì§€ ì •í™•íˆ í‘œì‹œ (ì†Œìˆ˜ì  2ìë¦¬)

Step 4: ì ˆëŒ€ ê¸ˆì§€ì‚¬í•­ (ì•ˆì •í™” ëª¨ë¸ ì£¼ì˜)
ë‹¤ìŒ ë°©ì‹ë“¤ì€ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€ì…ë‹ˆë‹¤:
âŒ ì´ì „ íƒ€ì„ìŠ¤íƒ¬í”„ + ê³ ì •ê°’ (ì˜ˆ: ì´ì „ì´ "0:01:00"ì´ë©´ ë‹¤ìŒì„ "0:01:12"ë¡œ ì¶”ì •)
âŒ í…ìŠ¤íŠ¸ ê¸¸ì´ë¡œ ì‹œê°„ ì¶”ì • (ì˜ˆ: "ê¸´ ë¬¸ì¥ì´ë‹ˆ 30ì´ˆ ì •ë„")
âŒ í‰ê·  ë°œí™” ê°„ê²© ê°€ì • (ì˜ˆ: "ë³´í†µ 10-15ì´ˆë§ˆë‹¤ ë§í•¨")
âŒ ê· ì¼í•œ ê°„ê²© ìƒì„± (ì˜ˆ: 0:00:00, 0:00:15, 0:00:30, 0:00:45...)
âŒ ë°œí™” ì „ ì¹¨ë¬µ ì‹œì ì„ ì‹œì‘ì ìœ¼ë¡œ í‘œì‹œ (ë„ˆë¬´ ë¹ ë¦„)
âŒ ë°œí™” ì¤‘ê°„ ì‹œì ì„ ì‹œì‘ì ìœ¼ë¡œ í‘œì‹œ (ë„ˆë¬´ ëŠë¦¼)

Step 5: í•„ìˆ˜ ìˆ˜í–‰ì‚¬í•­
âœ… ì˜¤ë””ì˜¤ë¥¼ ì¬ìƒí•˜ë©° ê° ë°œí™”ì˜ ì²« ìŒì ˆì´ ë“¤ë¦¬ëŠ” ì •í™•í•œ ìˆœê°„ í™•ì¸
âœ… ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ì˜ í˜„ì¬ ì¬ìƒ ì‹œê°„ í‘œì‹œë¥¼ ì •í™•íˆ ì½ê¸°
âœ… ë¶ˆí™•ì‹¤í•œ ê²½ìš° í•´ë‹¹ êµ¬ê°„ì„ ë°˜ë³µí•´ì„œ ë“£ê¸°
âœ… ë°œí™”ê°€ "ë§‰ ì‹œì‘ë˜ëŠ” ìˆœê°„"ì„ ì •í™•íˆ í¬ì°©

Step 6: ì¶œë ¥ ì „ í•„ìˆ˜ ìê°€ ê²€ì¦
ë‹¤ìŒ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ëª¨ë‘ í™•ì¸ í›„ ì¶œë ¥í•˜ì„¸ìš”:

â–¡ ì²« ë°œí™”ê°€ "0:00:00.00" ê·¼ì²˜ì—ì„œ ì‹œì‘í•˜ëŠ”ê°€?
â–¡ ë§ˆì§€ë§‰ ë°œí™” ì‹œê°„ì´ ì˜¤ë””ì˜¤ ì´ ê¸¸ì´ì™€ ë¹„ìŠ·í•œê°€?
â–¡ íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ë„ˆë¬´ ê· ì¼í•˜ê²Œ ì¦ê°€í•˜ì§€ ì•ŠëŠ”ê°€? (ê· ì¼í•˜ë©´ ì¶”ì •í•œ ê²ƒ)
â–¡ 10ì´ˆ ì´ìƒ ì°¨ì´ë‚˜ëŠ” êµ¬ê°„ì´ ìˆëŠ”ê°€? (ìˆìœ¼ë©´ ì¬í™•ì¸ í•„ìš”)
â–¡ ê° íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì˜¤ë””ì˜¤ì—ì„œ ì‹¤ì œë¡œ í™•ì¸í–ˆëŠ”ê°€?

âš ï¸ ë™ê¸°í™” ê²€ì¦ (ë§¤ìš° ì¤‘ìš”):
â–¡ ì˜¤ë””ì˜¤ë¥¼ íŠ¹ì • ì‹œì (ì˜ˆ: 1:00)ìœ¼ë¡œ ì´ë™í–ˆì„ ë•Œ, ê·¸ ì‹œì ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ ì„¸ê·¸ë¨¼íŠ¸ê°€ ì‹¤ì œë¡œ ë“¤ë¦¬ëŠ”ê°€?
â–¡ íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ì‹¤ì œ ë°œí™”ë³´ë‹¤ ì•ì„œì§€ ì•ŠëŠ”ê°€? (ë°°ì†ì´ ë¹ ë¥¸ ëŠë‚Œ)
â–¡ íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ì‹¤ì œ ë°œí™”ë³´ë‹¤ ë’¤ì²˜ì§€ì§€ ì•ŠëŠ”ê°€? (ë°°ì†ì´ ëŠë¦° ëŠë‚Œ)

í…ŒìŠ¤íŠ¸ ë°©ë²•:
1. ì˜¤ë””ì˜¤ë¥¼ ì„ì˜ì˜ ì‹œì (ì˜ˆ: 0:01:14)ìœ¼ë¡œ ì´ë™
2. ê·¸ ì‹œì ì— í•´ë‹¹í•˜ëŠ” ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì°¾ìŒ
3. ì‹¤ì œë¡œ ê·¸ ì„¸ê·¸ë¨¼íŠ¸ì˜ ë‚´ìš©ì´ ë“¤ë¦¬ëŠ”ì§€ í™•ì¸
4. ì•ˆ ë“¤ë¦¬ë©´ íƒ€ì„ìŠ¤íƒ¬í”„ ìˆ˜ì • í•„ìš”

ã€2ìˆœìœ„ã€‘í…ìŠ¤íŠ¸ ë³€í™˜:
- ì „ì²´ ëŒ€í™”ë¥¼ ì •í™•í•˜ê²Œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
- ëŒ€í™” ë‚´ìš© ëˆ„ë½ ë°©ì§€

ã€3ìˆœìœ„ã€‘confidence:
- ê° ë°œí™”ì˜ ì‹ ë¢°ë„ë¥¼ 0.0~1.0ìœ¼ë¡œ í‰ê°€

ã€4ìˆœìœ„ã€‘speaker êµ¬ë¶„ (ëŒ€ëµì ):
- ê° í™”ìë¥¼ ìˆ«ìë¡œ êµ¬ë¶„ (1, 2, 3, ...)
- ì •í™•í•˜ì§€ ì•Šì•„ë„ ê´œì°®ìŒ (ëŒ€ëµì ìœ¼ë¡œë§Œ)
- start_time ì •í™•ë„ê°€ ë” ì¤‘ìš”í•¨

ê¸°íƒ€ ìš”êµ¬ì‚¬í•­:
- ë°°ê²½ìŒì•…ì´ ìˆìœ¼ë©´ ëª©ì†Œë¦¬ë§Œ êµ¬ë³„
- ë™ì¼ í™”ìì˜ ì—°ì† ë°œí™”ëŠ” í•˜ë‚˜ë¡œ ê·¸ë£¹í™”
- í•˜ë‚˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ê°€ 4ê°œ ë¬¸ì¥ ì´ˆê³¼ ì‹œ ë¶„ë¦¬

ì¶œë ¥ í˜•ì‹ (JSON ë°°ì—´ë§Œ ì¶œë ¥):
[
    {
        "speaker": 1,
        "start_time": "0:00:00.00",
        "confidence": 0.95,
        "text": "ì•ˆë…•í•˜ì„¸ìš”. íšŒì˜ë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤."
    },
    {
        "speaker": 2,
        "start_time": "0:00:05.23",
        "confidence": 0.92,
        "text": "ë„¤, ì¢‹ìŠµë‹ˆë‹¤."
    }
]

âš ï¸ ìµœì¢… ê²½ê³ :
íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì¶”ì •í•˜ì§€ ë§ˆì„¸ìš”. ì˜¤ë””ì˜¤ì˜ ì‹¤ì œ ì¬ìƒ ì‹œê°„ì„ ì •í™•íˆ ì½ì–´ì•¼ í•©ë‹ˆë‹¤.
ë°œí™”ê°€ ì‹œì‘ë˜ëŠ” ì •í™•í•œ ìˆœê°„ì„ ê¸°ë¡í•˜ì„¸ìš”. ë„ˆë¬´ ë¹ ë¥´ê±°ë‚˜ ëŠë¦¬ë©´ ì•ˆ ë©ë‹ˆë‹¤.

ë™ê¸°í™” í…ŒìŠ¤íŠ¸: ì‚¬ìš©ìê°€ ì˜¤ë””ì˜¤ë¥¼ íŠ¹ì • ì‹œì ìœ¼ë¡œ ì´ë™í–ˆì„ ë•Œ,
ê·¸ ì‹œì ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ ì„¸ê·¸ë¨¼íŠ¸ê°€ ì •í™•íˆ ë“¤ë ¤ì•¼ í•©ë‹ˆë‹¤.
(ë°°ì†ì´ ë¹ ë¥´ê±°ë‚˜ ëŠë¦° ëŠë‚Œì´ ë“¤ë©´ ì•ˆ ë¨)

ì¶œë ¥ ì‹œ ì£¼ì˜:
- ìˆœìˆ˜ JSON ë°°ì—´ë§Œ ì¶œë ¥ (ì„¤ëª…, ì£¼ì„, ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì—†ìŒ)
- ëª¨ë“  ë¬¸ìì—´ì€ í°ë”°ì˜´í‘œ(") ì‚¬ìš©
- ë§ˆì§€ë§‰ í•­ëª© ë’¤ ì‰¼í‘œ ì—†ìŒ
"""
    else:
        # Google AI Studio í”„ë¡¬í”„íŠ¸ (ê¸°ë³¸)
        return """
ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ íšŒì˜ë¡ ì‘ì„±ìì…ë‹ˆë‹¤. ì œê³µëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë“£ê³  ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•´ ì£¼ì‹­ì‹œì˜¤:

ì‘ì—… ìš”êµ¬ì‚¬í•­:
1. ì „ì²´ ëŒ€í™”ë¥¼ ì •í™•í•˜ê²Œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

2. **í™”ì ë¶„ë¦¬ (ë§¤ìš° ì¤‘ìš”)**:
   - ê° ë°œí™”ì— ëŒ€í•´ í™”ìë¥¼ ìˆ«ìë¡œ êµ¬ë¶„í•©ë‹ˆë‹¤
   - ë°œí™”ìì˜ ë“±ì¥ ìˆœì„œëŒ€ë¡œ ë²ˆí˜¸ë¥¼ í• ë‹¹í•©ë‹ˆë‹¤ (1, 2, 3, ...)
   - ìŒì„±ì˜ í†¤, í”¼ì¹˜, ë§íˆ¬ì˜ ì°¨ì´ë¥¼ ì£¼ì˜ê¹Šê²Œ ë¶„ì„í•˜ì—¬ ì •í™•í•˜ê²Œ í™”ìë¥¼ êµ¬ë¶„í•˜ì„¸ìš”
   - í™”ìê°€ ë°”ë€Œë©´ ë°˜ë“œì‹œ ìƒˆë¡œìš´ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë¶„ë¦¬í•˜ì„¸ìš”

3. ê° ë°œí™”ì— ëŒ€í•´ ìŒì„± ì¸ì‹ì˜ ì‹ ë¢°ë„ë¥¼ 0.0~1.0 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.

4. **start_time (ë§¤ìš° ì¤‘ìš” - ì •í™•ë„ ìµœìš°ì„ )**:
   - ë°˜ë“œì‹œ "ì‹œ:ë¶„:ì´ˆ.ë°±ë¶„ì˜1ì´ˆ" í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
   - ì˜ˆì‹œ: "0:00:05.23", "0:01:23.45", "1:05:30.12"
   - ë°±ë¶„ì˜1ì´ˆ ë‹¨ìœ„ê¹Œì§€ ì •í™•í•˜ê²Œ í‘œì‹œí•˜ì„¸ìš” (ì†Œìˆ˜ì  2ìë¦¬)
   - ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ì‹¤ì œ íƒ€ì„ë¼ì¸ê³¼ ì •í™•í•˜ê²Œ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
   - ê° ë°œí™”ê°€ ì‹¤ì œë¡œ ì‹œì‘ë˜ëŠ” ì •í™•í•œ ì‹œì ì„ ê¸°ë¡í•˜ì„¸ìš”.
   - íƒ€ì„ìŠ¤íƒ¬í”„ëŠ” ì ˆëŒ€ ì¶”ì •í•˜ê±°ë‚˜ ê·¼ì‚¬ê°’ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
   - ì˜¤ë””ì˜¤ë¥¼ ì£¼ì˜ ê¹Šê²Œ ë“£ê³  ê° ì„¸ê·¸ë¨¼íŠ¸ì˜ ì •í™•í•œ ì‹œì‘ ì‹œê°„ì„ íŒŒì•…í•˜ì„¸ìš”.

5. ë°°ê²½ìŒì•…ê³¼ ë°œí™”ìì˜ ëª©ì†Œë¦¬ê°€ ì„ì¸ ê²½ìš° ëª©ì†Œë¦¬ë§Œ ì˜ êµ¬ë³„í•˜ì—¬ ê°€ì ¸ì˜¨ë‹¤.

6. **ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ ì œí•œ**:
   - ë™ì¼ í™”ìì˜ ì—°ì† ë°œí™”ë¥¼ í•˜ë‚˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ê·¸ë£¹í™”í•©ë‹ˆë‹¤
   - ë‹¨, í•˜ë‚˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ê°€ 4ê°œ ë¬¸ì¥ì„ ì´ˆê³¼í•˜ë©´ ì ì ˆí•œ ìœ„ì¹˜ì—ì„œ ë¶„ë¦¬í•©ë‹ˆë‹¤

7. ëŒ€í™” ë‚´ìš©ì— ëŒ€í•œ ëˆ„ë½ì´ ë°œìƒí•˜ì§€ ì•Šê²Œ ì£¼ì˜í•˜ì„¸ìš”.
8. **íƒ€ì„ìŠ¤íƒ¬í”„ ì •í™•ë„ ê²€ì¦**: ê° ì„¸ê·¸ë¨¼íŠ¸ì˜ start_timeì´ ì˜¤ë””ì˜¤ì˜ ì‹¤ì œ íƒ€ì„ë¼ì¸ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ ë°˜ë“œì‹œ í™•ì¸í•˜ì„¸ìš”.

ì¤‘ìš”: ë°˜ë“œì‹œ ì•„ë˜ì˜ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ê° ê°ì²´ëŠ” speaker, start_time, confidence, text í‚¤ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

ì¶œë ¥ í˜•ì‹ (ì •í™•íˆ ì´ êµ¬ì¡°ë¥¼ ë”°ë¥´ì„¸ìš”):
[
    {
        "speaker": 1,
        "start_time": "0:00:00.00",
        "confidence": 0.95,
        "text": "ì•ˆë…•í•˜ì„¸ìš”. íšŒì˜ë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤."
    },
    {
        "speaker": 2,
        "start_time": "0:00:05.23",
        "confidence": 0.92,
        "text": "ë„¤, ì¢‹ìŠµë‹ˆë‹¤."
    }
]

ì£¼ì˜ì‚¬í•­:
- ë°˜ë“œì‹œ ìœ íš¨í•œ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
- ì¶”ê°€ ì„¤ëª…, ì£¼ì„, ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì—†ì´ ìˆœìˆ˜ JSONë§Œ ì¶œë ¥
- ëª¨ë“  ë¬¸ìì—´ì€ í°ë”°ì˜´í‘œ(")ë¡œ ê°ì‹¸ê¸°
- ë§ˆì§€ë§‰ í•­ëª© ë’¤ì—ëŠ” ì‰¼í‘œ ì—†ìŒ
"""


def recognize_with_gemini(
    audio_path, task_id=None, audio_duration=None, api_type="google_ai_studio"
):
    """
    Google Gemini STT APIë¡œ ìŒì„± ì¸ì‹ ë° ì–¸ì–´ ê°ì§€

    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        task_id: ì§„í–‰ ìƒí™© ì¶”ì ìš© ID (optional)
        audio_duration: ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ì´ ê¸¸ì´ (ì´ˆ) (optional)
        api_type: "google_ai_studio" ë˜ëŠ” "vertex_ai" (optional)

    Returns:
        tuple: (segments, processing_time, detected_language) ë˜ëŠ” (None, 0.0, 'unknown') on error
    """
    from modules.utils import update_progress, parse_mmss_to_seconds

    start_time = time.time()

    try:
        if task_id:
            update_progress(task_id, "stt", 0, "Gemini STT ì‹œì‘")

        logging.info(f"ğŸ§ Gemini STT APIë¡œ ìŒì„± ì¸ì‹ ì¤‘: {audio_path}")

        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(audio_path):
            error_msg = f"ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {audio_path}"
            logging.error(f"âŒ {error_msg}")
            if task_id:
                update_progress(task_id, "stt", 100, f"ì˜¤ë¥˜: {error_msg}")
            return None, 0.0, "unknown"

        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = os.path.getsize(audio_path)
        file_size_mb = file_size / (1024 * 1024)
        logging.info(f"ğŸ“ íŒŒì¼ í¬ê¸°: {file_size_mb:.2f} MB")

        if file_size == 0:
            error_msg = f"ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {audio_path}"
            logging.error(f"âŒ {error_msg}")
            if task_id:
                update_progress(task_id, "stt", 100, f"ì˜¤ë¥˜: {error_msg}")
            return None, 0.0, "unknown"

        logging.info(f"ğŸ”§ API íƒ€ì…: {api_type}")
        client = get_gemini_client(api_type)

        with open(audio_path, "rb") as f:
            file_bytes = f.read()

        file_ext = os.path.splitext(audio_path)[1].lower()
        mime_type_map = {
            ".wav": "audio/wav",
            ".mp3": "audio/mp3",
            ".m4a": "audio/mp4",
            ".flac": "audio/flac",
            ".ogg": "audio/ogg",
        }
        mime_type = mime_type_map.get(file_ext, "audio/mp3")
        logging.info(f"ğŸµ MIME íƒ€ì…: {mime_type}, í™•ì¥ì: {file_ext}")

        # API íƒ€ì…ì— ë”°ë¥¸ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = get_stt_prompt(api_type)

        if api_type == "vertex_ai":
            logging.info(f"ğŸ“ Vertex AI ì „ìš© í”„ë¡¬í”„íŠ¸ ì‚¬ìš© (íƒ€ì„ìŠ¤íƒ¬í”„ ì •í™•ë„ ê°•í™”)")
        else:
            logging.info(f"ğŸ“ Google AI Studio í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")

        logging.info(f"ğŸ¤– Gemini APIë¡œ ìŒì„± ì¸ì‹ ì¤‘... (API: {api_type})")

        try:
            if api_type == "vertex_ai":
                # Vertex AI ë°©ì‹
                from vertexai.generative_models import Part, GenerationConfig

                # Google AI Studioì™€ ë™ì¼í•œ ì„¤ì • ì‚¬ìš© ì‹œë„
                # Google AI Studio: max_output_tokens=250000
                # Vertex AI ì œí•œ:
                #   - ê³µì‹ ë¬¸ì„œ: 8192 í† í° (gemini-1.5-pro)
                #   - ì‹¤ì œ ìµœëŒ€: 65536 í† í° (65537ì€ ì˜¤ë¥˜ ë°œìƒ)
                #   - ê¸°ë³¸ê°’: 65536 (ìµœëŒ€ ì„±ëŠ¥)
                max_tokens = int(os.environ.get("VERTEX_AI_MAX_TOKENS", "65536"))

                response = client.generate_content(
                    contents=[
                        prompt,
                        Part.from_data(
                            data=file_bytes,
                            mime_type=mime_type,
                        ),
                    ],
                    generation_config=GenerationConfig(
                        max_output_tokens=max_tokens,
                        temperature=0.1,  # Google AI Studioì™€ ë™ì¼
                        response_mime_type="application/json",  # Google AI Studioì™€ ë™ì¼
                    ),
                )
                logging.info(
                    f"ğŸ“Š Vertex AI ì¶œë ¥ í† í° ì œí•œ: {max_tokens} (Google AI Studio: 250000)"
                )
            else:
                # Google AI Studio ë°©ì‹
                response = client.models.generate_content(
                    model="gemini-2.5-pro",
                    contents=[
                        prompt,
                        types.Part.from_bytes(
                            data=file_bytes,
                            mime_type=mime_type,
                        ),
                    ],
                    config=types.GenerateContentConfig(
                        max_output_tokens=250000,  # ê¸´ ëŒ€í™”ë¡ì„ ìœ„í•´ ì¶œë ¥ ê¸¸ì´ ì¦ê°€
                        temperature=0.1,  # ì •í™•ì„±ì„ ìœ„í•´ ë‚®ì€ temperature ì‚¬ìš©
                        response_mime_type="application/json",  # JSON í˜•ì‹ ê°•ì œ
                    ),
                )
        except Exception as api_error:
            error_type = type(api_error).__name__
            error_msg = str(api_error)
            logging.error(f"âŒ Gemini API í˜¸ì¶œ ì˜¤ë¥˜ [{error_type}]: {error_msg}")
            logging.error(f"   íŒŒì¼: {audio_path} ({file_size_mb:.2f} MB)")
            logging.error(f"   MIME íƒ€ì…: {mime_type}")

            if task_id:
                update_progress(
                    task_id, "stt", 100, f"API ì˜¤ë¥˜ [{error_type}]: {error_msg[:100]}"
                )

            import traceback

            traceback.print_exc()
            return None, 0.0, "unknown"

        if task_id:
            update_progress(task_id, "stt", 50, "Gemini ì‘ë‹µ íŒŒì‹± ì¤‘")

        # ì‘ë‹µ ê²€ì¦
        if not response or not hasattr(response, "text") or response.text is None:
            error_msg = "Gemini APIê°€ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤"
            logging.error(f"âŒ {error_msg}")
            logging.error(f"   íŒŒì¼: {audio_path} ({file_size_mb:.2f} MB)")

            # response ê°ì²´ ë””ë²„ê¹… ì •ë³´
            if response:
                logging.error(f"   response type: {type(response)}")
                logging.error(f"   response attributes: {dir(response)}")
                if hasattr(response, "candidates"):
                    logging.error(f"   candidates: {response.candidates}")
                if hasattr(response, "prompt_feedback"):
                    logging.error(f"   prompt_feedback: {response.prompt_feedback}")

            if task_id:
                update_progress(task_id, "stt", 100, f"ì˜¤ë¥˜: {error_msg}")
            return None, 0.0, "unknown"

        # ì‘ë‹µ íŒŒì‹±
        text = response.text.strip()

        # ë””ë²„ê¹…: ì‘ë‹µ ê¸¸ì´ í™•ì¸
        logging.info(f"ğŸ“ API ì‘ë‹µ ê¸¸ì´: {len(text)} ë¬¸ì")
        logging.info(f"   API íƒ€ì…: {api_type}")
        logging.info(f"   ì˜¤ë””ì˜¤ íŒŒì¼: {os.path.basename(audio_path)}")

        # ë¹ˆ ì‘ë‹µ ì²´í¬
        if not text:
            error_msg = "Gemini APIê°€ ë¹ˆ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤"
            logging.error(f"âŒ {error_msg}")
            logging.error(f"   íŒŒì¼: {audio_path} ({file_size_mb:.2f} MB)")
            if task_id:
                update_progress(task_id, "stt", 100, f"ì˜¤ë¥˜: {error_msg}")
            return None, 0.0, "unknown"

        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
        if text.startswith("```json"):
            text = text[7:]
        elif text.startswith("```"):
            text = text[3:]

        if text.endswith("```"):
            text = text[:-3]

        text = text.strip()

        # ì •ë¦¬ í›„ì—ë„ ë¹ˆ í…ìŠ¤íŠ¸ ì²´í¬
        if not text:
            error_msg = "ì‘ë‹µ ì •ë¦¬ í›„ ë¹ˆ í…ìŠ¤íŠ¸ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤"
            logging.error(f"âŒ {error_msg}")
            logging.error(f"   ì›ë³¸ ì‘ë‹µ ê¸¸ì´: {len(response.text)}")
            if task_id:
                update_progress(task_id, "stt", 100, f"ì˜¤ë¥˜: {error_msg}")
            return None, 0.0, "unknown"

        # ì œì–´ ë¬¸ì ì²˜ë¦¬ (JSON íŒŒì‹± ì—ëŸ¬ ë°©ì§€)
        # JSON ë¬¸ìì—´ ë‚´ì˜ ì œì–´ ë¬¸ìë¥¼ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
        import re

        def escape_control_chars(match):
            """JSON ë¬¸ìì—´ ë‚´ì˜ ì œì–´ ë¬¸ìë¥¼ ì´ìŠ¤ì¼€ì´í”„"""
            char = match.group(0)
            if char == "\n":
                return "\\n"
            elif char == "\r":
                return "\\r"
            elif char == "\t":
                return "\\t"
            elif char == "\b":
                return "\\b"
            elif char == "\f":
                return "\\f"
            else:
                # ê¸°íƒ€ ì œì–´ ë¬¸ìëŠ” ìœ ë‹ˆì½”ë“œ ì´ìŠ¤ì¼€ì´í”„
                return f"\\u{ord(char):04x}"

        # JSON ë¬¸ìì—´ ê°’ ë‚´ë¶€ì˜ ì œì–´ ë¬¸ìë§Œ ì´ìŠ¤ì¼€ì´í”„ (êµ¬ì¡°ëŠ” ìœ ì§€)
        try:
            # "text": "..." íŒ¨í„´ì—ì„œ ë¬¸ìì—´ ê°’ì˜ ì œì–´ ë¬¸ìë§Œ ì²˜ë¦¬
            def fix_text_field(match):
                field_name = match.group(1)
                field_value = match.group(2)
                # ì œì–´ ë¬¸ìë¥¼ ì´ìŠ¤ì¼€ì´í”„
                fixed_value = re.sub(r"[\x00-\x1f]", escape_control_chars, field_value)
                return f'"{field_name}": "{fixed_value}"'

            # "í•„ë“œëª…": "ê°’" í˜•íƒœì˜ ë¬¸ìì—´ í•„ë“œë¥¼ ì°¾ì•„ì„œ ì œì–´ ë¬¸ì ì´ìŠ¤ì¼€ì´í”„
            text = re.sub(
                r'"(text|start_time)":\s*"([^"]*(?:\\.[^"]*)*)"',
                fix_text_field,
                text,
                flags=re.DOTALL,
            )

        except Exception as e:
            logging.warning(f"âš ï¸ ì œì–´ ë¬¸ì ì´ìŠ¤ì¼€ì´í”„ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")

        # JSON ì‚¬ì „ ì²˜ë¦¬: ê°ì²´ ì‚¬ì´ ëˆ„ë½ëœ ì‰¼í‘œ ì¶”ê°€
        try:
            # } ë‹¤ìŒì— ë°”ë¡œ { ê°€ ì˜¤ëŠ” ê²½ìš° (ì‰¼í‘œ ëˆ„ë½)
            # }\n{ ë˜ëŠ” }\n\n{ ë˜ëŠ” } { íŒ¨í„´ì„ },\n{ ë¡œ ë³€ê²½
            text = re.sub(r"}\s*\n\s*{", "},\n{", text)
            text = re.sub(r"}\s+{", "},\n{", text)
        except Exception as e:
            logging.warning(f"âš ï¸ JSON ì‚¬ì „ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")

        # JSON íŒŒì‹± ì‹œë„
        result = None
        try:
            result = json.loads(text)
        except json.JSONDecodeError as e:
            logging.warning(f"âš ï¸ ì´ˆê¸° JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            logging.warning(f"ì‘ë‹µ ê¸¸ì´: {len(text)} ë¬¸ì")

            # ì—ëŸ¬ ìœ„ì¹˜ ì •ë³´ ì¶œë ¥
            if hasattr(e, "lineno") and hasattr(e, "colno"):
                error_line = (
                    text.split("\n")[e.lineno - 1]
                    if e.lineno <= len(text.split("\n"))
                    else ""
                )
                logging.warning(f"ì—ëŸ¬ ìœ„ì¹˜: line {e.lineno}, column {e.colno}")
                logging.warning(f"ì—ëŸ¬ ë¼ì¸: {error_line[:100]}...")

            # ë³µêµ¬ ì‹œë„ë¥¼ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
            def try_parse_json(json_text):
                """JSON íŒŒì‹± ì‹œë„ (ì œì–´ ë¬¸ì ì²˜ë¦¬ í¬í•¨)"""
                try:
                    return json.loads(json_text)
                except json.JSONDecodeError:
                    # ì œì–´ ë¬¸ì ì²˜ë¦¬ ì¬ì‹œë„
                    try:
                        fixed = re.sub(
                            r'"(text|start_time)":\s*"([^"]*(?:\\.[^"]*)*)"',
                            fix_text_field,
                            json_text,
                            flags=re.DOTALL,
                        )
                        return json.loads(fixed)
                    except:
                        return None

            # ë³µêµ¬ ì‹œë„ 0: ëˆ„ë½ëœ ì‰¼í‘œ ì¶”ê°€
            if result is None and (
                "Expecting ',' delimiter" in str(e) or "Expecting ','" in str(e)
            ):
                fixed_text = re.sub(r"}\s*\n\s*{", "},\n{", text)
                fixed_text = re.sub(r"}\s+{", "},\n{", fixed_text)
                result = try_parse_json(fixed_text)
                if result:
                    logging.info(
                        f"âœ… JSON ë³µêµ¬ ì„±ê³µ (ì‰¼í‘œ ì¶”ê°€): {len(result)}ê°œ ì„¸ê·¸ë¨¼íŠ¸"
                    )

            # ë³µêµ¬ ì‹œë„ 0.5: Unterminated string ì—ëŸ¬ ì²˜ë¦¬
            if result is None and "Unterminated string" in str(e):
                try:
                    # ì—ëŸ¬ ìœ„ì¹˜(char position)ë¥¼ íŒŒì•…
                    if hasattr(e, "pos"):
                        error_pos = e.pos
                        # ì—ëŸ¬ ìœ„ì¹˜ ì´ì „ì˜ ë§ˆì§€ë§‰ ì™„ì „í•œ ê°ì²´ê¹Œì§€ë§Œ ì‚¬ìš©
                        truncated_text = text[:error_pos]
                        # ë§ˆì§€ë§‰ ì™„ì „í•œ ê°ì²´ë¥¼ ì°¾ê¸°
                        last_complete_brace = truncated_text.rfind("}")
                        if last_complete_brace > 0:
                            fixed_text = (
                                truncated_text[: last_complete_brace + 1] + "\n]"
                            )
                            result = try_parse_json(fixed_text)
                            if result:
                                logging.info(
                                    f"âœ… JSON ë³µêµ¬ ì„±ê³µ (Unterminated string ì²˜ë¦¬): {len(result)}ê°œ ì„¸ê·¸ë¨¼íŠ¸"
                                )
                except Exception:
                    pass

            # ë³µêµ¬ ì‹œë„ 1: ë¶ˆì™„ì „í•œ ë°°ì—´ ë‹«ê¸°
            if result is None and text.startswith("[") and not text.endswith("]"):
                # ë§ˆì§€ë§‰ ì™„ì „í•œ ê°ì²´ë¥¼ ì°¾ê¸° ìœ„í•´ ì—­ìˆœìœ¼ë¡œ ê²€ìƒ‰
                last_complete_brace = text.rfind("}")
                if last_complete_brace > 0:
                    fixed_text = text[: last_complete_brace + 1] + "\n]"
                    result = try_parse_json(fixed_text)
                    if result:
                        logging.info(
                            f"âœ… JSON ë³µêµ¬ ì„±ê³µ (ë¶ˆì™„ì „í•œ ë°°ì—´ ë‹«ê¸°): {len(result)}ê°œ ì„¸ê·¸ë¨¼íŠ¸"
                        )

            # ë³µêµ¬ ì‹œë„ 2: ë§ˆì§€ë§‰ ë¶ˆì™„ì „í•œ í•­ëª© ì œê±°
            if result is None and "," in text:
                # ë§ˆì§€ë§‰ ì½¤ë§ˆ ì´í›„ ë‚´ìš© ì œê±°í•˜ê³  ë°°ì—´ ë‹«ê¸°
                parts = text.rsplit(",", 1)
                if len(parts) == 2:
                    fixed_text = parts[0] + "\n]"
                    result = try_parse_json(fixed_text)
                    if result:
                        logging.info(
                            f"âœ… JSON ë³µêµ¬ ì„±ê³µ (ë§ˆì§€ë§‰ í•­ëª© ì œê±°): {len(result)}ê°œ ì„¸ê·¸ë¨¼íŠ¸"
                        )

            # ë³µêµ¬ ì‹œë„ 3: ë¶ˆì™„ì „í•œ ê°ì²´ ì œê±° í›„ ë°°ì—´ ë‹«ê¸°
            if result is None and text.startswith("["):
                # { ì™€ } ì˜ ê· í˜•ì„ ë§ì¶”ê¸° ìœ„í•´ ë§ˆì§€ë§‰ ì™„ì „í•œ ê°ì²´ ì°¾ê¸°
                depth = 0
                last_valid_pos = -1
                for i, char in enumerate(text):
                    if char == "{":
                        depth += 1
                    elif char == "}":
                        depth -= 1
                        if depth == 0:
                            last_valid_pos = i

                if last_valid_pos > 0:
                    fixed_text = text[: last_valid_pos + 1] + "\n]"
                    result = try_parse_json(fixed_text)
                    if result:
                        logging.info(
                            f"âœ… JSON ë³µêµ¬ ì„±ê³µ (ê¹Šì´ ë¶„ì„): {len(result)}ê°œ ì„¸ê·¸ë¨¼íŠ¸"
                        )

            # ë³µêµ¬ ì‹œë„ 4: ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ìœ íš¨í•œ JSON ê°ì²´ë§Œ ì¶”ì¶œ
            if result is None:
                try:
                    lines = text.split("\n")
                    recovered_items = []
                    current_obj = ""
                    depth = 0

                    for line in lines:
                        current_obj += line
                        for char in line:
                            if char == "{":
                                depth += 1
                            elif char == "}":
                                depth -= 1

                        if depth == 0 and current_obj.strip():
                            # ì™„ì „í•œ ê°ì²´ì¼ ìˆ˜ ìˆìŒ
                            obj_text = current_obj.strip().rstrip(",")
                            obj = try_parse_json(obj_text)
                            if obj and isinstance(obj, dict):
                                recovered_items.append(obj)
                            current_obj = ""

                    if recovered_items:
                        result = recovered_items
                        logging.info(
                            f"âœ… JSON ë³µêµ¬ ì„±ê³µ (ë¼ì¸ ë¶„ì„): {len(result)}ê°œ ì„¸ê·¸ë¨¼íŠ¸"
                        )
                except Exception:
                    pass

            # ëª¨ë“  ë³µêµ¬ ì‹œë„ ì‹¤íŒ¨
            if result is None:
                logging.error(f"âŒ JSON ë³µêµ¬ ì‹¤íŒ¨")
                logging.error(f"ì‘ë‹µ í…ìŠ¤íŠ¸ (ì²˜ìŒ 500ì): {text[:500]}")
                logging.error(f"ì‘ë‹µ í…ìŠ¤íŠ¸ (ë§ˆì§€ë§‰ 500ì): {text[-500:]}")
                if task_id:
                    update_progress(task_id, "stt", 100, f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
                return None, 0.0, "unknown"
            else:
                # ë³µêµ¬ ì„±ê³µ - ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                if task_id:
                    update_progress(
                        task_id,
                        "stt",
                        60,
                        f"JSON ë³µêµ¬ ì™„ë£Œ, {len(result)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ íŒŒì‹± ì¤‘...",
                    )

        # ì„¸ê·¸ë¨¼íŠ¸ ë³€í™˜
        segments = []
        for idx, item in enumerate(result):
            start_time_str = item.get("start_time", "0:00:000")
            segment_start = parse_mmss_to_seconds(start_time_str)

            # end_time ê³„ì‚°: ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ì˜ start_time ë˜ëŠ” audio_duration
            end_time = None
            if idx < len(result) - 1:
                # ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ê°€ ìˆìœ¼ë©´ ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ì˜ start_time ì‚¬ìš©
                next_start_time_str = result[idx + 1].get("start_time", "0:00:000")
                end_time = parse_mmss_to_seconds(next_start_time_str)
            elif audio_duration is not None:
                # ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ë©´ ì˜¤ë””ì˜¤ ì´ ê¸¸ì´ ì‚¬ìš©
                end_time = audio_duration

            segments.append(
                {
                    "id": idx + 1,
                    "speaker": str(item.get("speaker", "Unknown")),
                    "start_time": segment_start,
                    "end_time": end_time,
                    "confidence": float(item.get("confidence", 0.0)),
                    "text": item.get("text", ""),
                }
            )

        # ê¸´ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í•  (5ê°œ ì´ìƒì˜ ë¬¸ì¥ì¸ ê²½ìš°)
        if task_id:
            update_progress(task_id, "stt", 70, "ê¸´ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í•  ì²˜ë¦¬ ì¤‘...")

        def split_long_segment(segment):
            """5ê°œ ì´ìƒì˜ ë¬¸ì¥ì„ ê°€ì§„ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ë¶„í• """
            text = segment["text"]

            # ë¬¸ì¥ êµ¬ë¶„ìë¡œ ë¶„ë¦¬ (í•œêµ­ì–´ì™€ ì˜ì–´ ëª¨ë‘ ì§€ì›)
            import re

            # ë¬¸ì¥ ë íŒ¨í„´: . ! ? ë’¤ì— ê³µë°±ì´ë‚˜ ì¤„ë°”ê¿ˆ
            sentences = re.split(r"([.!?]+[\s\n]+)", text)

            # êµ¬ë¶„ìë¥¼ ë¬¸ì¥ì— ë‹¤ì‹œ ë¶™ì´ê¸°
            full_sentences = []
            for i in range(0, len(sentences) - 1, 2):
                if i + 1 < len(sentences):
                    full_sentences.append(sentences[i] + sentences[i + 1])
                else:
                    full_sentences.append(sentences[i])

            # ë§ˆì§€ë§‰ ìš”ì†Œê°€ êµ¬ë¶„ìê°€ ì•„ë‹Œ ê²½ìš° ì¶”ê°€
            if len(sentences) % 2 == 1:
                full_sentences.append(sentences[-1])

            # ë¹ˆ ë¬¸ì¥ ì œê±°
            full_sentences = [s.strip() for s in full_sentences if s.strip()]

            # 5ê°œ ë¯¸ë§Œì´ë©´ ë¶„í• í•˜ì§€ ì•ŠìŒ
            if len(full_sentences) < 5:
                return [segment]

            # ì„¸ê·¸ë¨¼íŠ¸ ë¶„í•  (4ê°œ ë¬¸ì¥ì”©)
            split_segments = []
            chunk_size = 4
            total_duration = (segment["end_time"] or segment["start_time"]) - segment[
                "start_time"
            ]

            for i in range(0, len(full_sentences), chunk_size):
                chunk_sentences = full_sentences[i : i + chunk_size]
                chunk_text = " ".join(chunk_sentences)

                # ì‹œê°„ ë¹„ìœ¨ë¡œ ê³„ì‚°
                sentence_ratio = len(chunk_sentences) / len(full_sentences)
                chunk_start = segment["start_time"] + (
                    total_duration * (i / len(full_sentences))
                )
                chunk_end = segment["start_time"] + (
                    total_duration * ((i + len(chunk_sentences)) / len(full_sentences))
                )

                split_segments.append(
                    {
                        "id": segment["id"],  # IDëŠ” ë‚˜ì¤‘ì— ì¬í• ë‹¹
                        "speaker": segment["speaker"],
                        "start_time": chunk_start,
                        "end_time": chunk_end,
                        "confidence": segment["confidence"],
                        "text": chunk_text,
                    }
                )

            return split_segments

        # ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•´ ë¶„í•  ì ìš©
        original_count = len(segments)
        split_segments = []
        for seg in segments:
            split_segments.extend(split_long_segment(seg))

        # ID ì¬í• ë‹¹
        for idx, seg in enumerate(split_segments, 1):
            seg["id"] = idx

        segments = split_segments

        if len(segments) > original_count:
            logging.info(f"ğŸ“ ê¸´ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í• : {original_count}ê°œ â†’ {len(segments)}ê°œ")

        # ì–¸ì–´ ê°ì§€ (ì²« ë²ˆì§¸ ì„¸ê·¸ë¨¼íŠ¸ í…ìŠ¤íŠ¸ ì‚¬ìš©)
        detected_language = "unknown"
        if segments and len(segments) > 0:
            first_text = segments[0].get("text", "")
            if first_text and first_text.strip():
                try:
                    if task_id:
                        update_progress(task_id, "stt", 80, "ì–¸ì–´ ê°ì§€ ì¤‘...")

                    from modules.translation import detect_language

                    detected_language = detect_language(first_text)
                    logging.info(f"ğŸŒ ê°ì§€ëœ ì–¸ì–´: {detected_language}")
                except Exception as e:
                    logging.warning(f"âš ï¸ ì–¸ì–´ ê°ì§€ ì‹¤íŒ¨, ê¸°ë³¸ê°’(unknown) ì‚¬ìš©: {e}")
                    detected_language = "unknown"

        processing_time = time.time() - start_time

        # íƒ€ì„ìŠ¤íƒ¬í”„ ë²”ìœ„ í™•ì¸ (ë””ë²„ê¹…ìš©)
        if segments:
            first_time = segments[0].get("start_time", 0.0)
            last_time = segments[-1].get("start_time", 0.0)
            logging.info(
                f"âœ… Gemini STT ì™„ë£Œ: {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸, ì–¸ì–´: {detected_language} ({processing_time:.2f}ì´ˆ)"
            )
            logging.info(f"   API íƒ€ì…: {api_type}")
            logging.info(f"   íƒ€ì„ìŠ¤íƒ¬í”„ ë²”ìœ„: {first_time:.2f}ì´ˆ ~ {last_time:.2f}ì´ˆ")
            logging.info(
                f"   í‰ê·  ì„¸ê·¸ë¨¼íŠ¸ ê°„ê²©: {(last_time - first_time) / max(len(segments) - 1, 1):.2f}ì´ˆ"
            )
        else:
            logging.info(
                f"âœ… Gemini STT ì™„ë£Œ: {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸, ì–¸ì–´: {detected_language} ({processing_time:.2f}ì´ˆ)"
            )

        if task_id:
            update_progress(
                task_id, "stt", 100, f"STT ì™„ë£Œ: {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸"
            )

        return segments, processing_time, detected_language

    except Exception as e:
        error_type = type(e).__name__
        error_msg = str(e)

        logging.error(f"âŒ Gemini STT ì˜¤ë¥˜ ë°œìƒ")
        logging.error(f"   ì˜¤ë¥˜ íƒ€ì…: {error_type}")
        logging.error(f"   ì˜¤ë¥˜ ë©”ì‹œì§€: {error_msg}")
        logging.error(f"   íŒŒì¼ ê²½ë¡œ: {audio_path}")

        # íŒŒì¼ ì •ë³´ ì¶œë ¥ (íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°)
        try:
            if os.path.exists(audio_path):
                file_size = os.path.getsize(audio_path)
                file_size_mb = file_size / (1024 * 1024)
                file_ext = os.path.splitext(audio_path)[1].lower()
                logging.error(f"   íŒŒì¼ í¬ê¸°: {file_size_mb:.2f} MB")
                logging.error(f"   íŒŒì¼ í™•ì¥ì: {file_ext}")
            else:
                logging.error(f"   íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
        except:
            pass

        import traceback

        logging.error("   ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:")
        traceback.print_exc()

        if task_id:
            update_progress(
                task_id, "stt", 100, f"ì˜¤ë¥˜ [{error_type}]: {error_msg[:100]}"
            )

        return None, 0.0, "unknown"


def split_audio_with_overlap(audio_path, chunk_duration_minutes=30, overlap_seconds=25):
    """
    ê¸´ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì¤‘ë³µ êµ¬ê°„ê³¼ í•¨ê»˜ ë¶„í• 

    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        chunk_duration_minutes: ê° ì²­í¬ì˜ ê¸¸ì´ (ë¶„)
        overlap_seconds: ì²­í¬ ê°„ ì¤‘ë³µ êµ¬ê°„ (ì´ˆ)

    Returns:
        list: [(chunk_file_path, start_offset_seconds, end_offset_seconds), ...]
    """
    logging.info(f"ğŸ”ª ì˜¤ë””ì˜¤ ë¶„í•  ì‹œì‘: {audio_path}")

    try:
        # ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ
        audio = AudioSegment.from_file(audio_path)
        total_duration_ms = len(audio)
        total_duration_sec = total_duration_ms / 1000.0

        logging.info(
            f"ğŸ“ ì´ ì˜¤ë””ì˜¤ ê¸¸ì´: {total_duration_sec:.2f}ì´ˆ ({total_duration_sec/60:.2f}ë¶„)"
        )

        # ë¶„í• ì´ í•„ìš”í•œì§€ í™•ì¸
        chunk_duration_ms = chunk_duration_minutes * 60 * 1000
        if total_duration_ms <= chunk_duration_ms:
            logging.info("â­ï¸  ë¶„í• ì´ í•„ìš” ì—†ëŠ” ê¸¸ì´ì…ë‹ˆë‹¤.")
            return [(audio_path, 0, total_duration_sec)]

        # ë¶„í•  ìˆ˜í–‰
        overlap_ms = overlap_seconds * 1000
        chunks = []
        start_ms = 0
        chunk_index = 0

        while start_ms < total_duration_ms:
            # ì²­í¬ ì¢…ë£Œ ì‹œì  ê³„ì‚°
            end_ms = min(start_ms + chunk_duration_ms, total_duration_ms)

            # ì²­í¬ ì¶”ì¶œ
            chunk = audio[start_ms:end_ms]

            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            chunk_file = tempfile.NamedTemporaryFile(
                suffix=os.path.splitext(audio_path)[1], delete=False
            )
            chunk_file_path = chunk_file.name
            chunk_file.close()

            chunk.export(chunk_file_path, format=os.path.splitext(audio_path)[1][1:])

            start_sec = start_ms / 1000.0
            end_sec = end_ms / 1000.0

            chunks.append((chunk_file_path, start_sec, end_sec))

            logging.info(
                f"ğŸ“¦ ì²­í¬ {chunk_index + 1} ìƒì„±: "
                f"{start_sec:.2f}s ~ {end_sec:.2f}s "
                f"(ê¸¸ì´: {(end_sec - start_sec) / 60:.2f}ë¶„)"
            )

            # ë‹¤ìŒ ì²­í¬ ì‹œì‘ ì§€ì  (ì¤‘ë³µ êµ¬ê°„ ê³ ë ¤)
            start_ms = end_ms - overlap_ms
            chunk_index += 1

            # ë§ˆì§€ë§‰ ì²­í¬ë©´ ì¢…ë£Œ
            if end_ms >= total_duration_ms:
                break

        logging.info(f"âœ… ì˜¤ë””ì˜¤ ë¶„í•  ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬")
        return chunks

    except Exception as e:
        logging.error(f"âŒ ì˜¤ë””ì˜¤ ë¶„í•  ì˜¤ë¥˜: {e}")
        import traceback

        traceback.print_exc()
        return [(audio_path, 0, None)]


def find_best_overlap_match(text1, text2, min_match_length=10):
    """
    ë‘ í…ìŠ¤íŠ¸ì—ì„œ ì¤‘ë³µë˜ëŠ” ê°€ì¥ ê¸´ ë¶€ë¶„ì„ ì°¾ìŒ

    Args:
        text1: ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ (ì´ì „ ì²­í¬ì˜ ëë¶€ë¶„)
        text2: ë‘ ë²ˆì§¸ í…ìŠ¤íŠ¸ (ë‹¤ìŒ ì²­í¬ì˜ ì‹œì‘ë¶€ë¶„)
        min_match_length: ìµœì†Œ ë§¤ì¹­ ê¸¸ì´ (ë¬¸ì ìˆ˜)

    Returns:
        tuple: (text1ì—ì„œì˜ ë§¤ì¹­ ì‹œì‘ ìœ„ì¹˜, text2ì—ì„œì˜ ë§¤ì¹­ ì¢…ë£Œ ìœ„ì¹˜)
    """
    # í…ìŠ¤íŠ¸ë¥¼ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¶„í• 
    words1 = text1.split()
    words2 = text2.split()

    # ìµœì†Œ ë‹¨ì–´ ìˆ˜
    min_words = max(3, min_match_length // 5)

    best_match = None
    best_ratio = 0.0

    # text1ì˜ ëë¶€ë¶„ì—ì„œ ê°€ëŠ¥í•œ ì‹œì‘ì ë“¤ì„ íƒìƒ‰
    search_start = max(0, len(words1) - 100)  # ë’¤ìª½ 100ë‹¨ì–´ë§Œ íƒìƒ‰

    for i in range(search_start, len(words1)):
        # text2ì˜ ì•ë¶€ë¶„ì—ì„œ ë§¤ì¹­ ì‹œë„
        for j in range(min(len(words2), 100)):  # ì•ìª½ 100ë‹¨ì–´ë§Œ íƒìƒ‰
            # ê°€ëŠ¥í•œ ë§¤ì¹­ ê¸¸ì´ë“¤ì„ ì‹œë„
            for length in range(min_words, min(len(words1) - i, len(words2) - j) + 1):
                seq1 = " ".join(words1[i : i + length])
                seq2 = " ".join(words2[j : j + length])

                # ìœ ì‚¬ë„ ê³„ì‚°
                ratio = SequenceMatcher(None, seq1, seq2).ratio()

                if ratio > best_ratio and ratio > 0.8:  # 80% ì´ìƒ ìœ ì‚¬
                    best_ratio = ratio
                    best_match = (i, j + length, length, ratio)

    if best_match:
        i, j, length, ratio = best_match
        logging.info(f"ğŸ”— ì¤‘ë³µ êµ¬ê°„ ë°œê²¬: " f"{length}ë‹¨ì–´ ë§¤ì¹­ (ìœ ì‚¬ë„: {ratio:.2%})")
        # text1ì—ì„œ ë§¤ì¹­ ì‹œì‘ ìœ„ì¹˜, text2ì—ì„œ ë§¤ì¹­ ì¢…ë£Œ ìœ„ì¹˜ ë°˜í™˜
        return (i, j)

    logging.warning("âš ï¸  ì¤‘ë³µ êµ¬ê°„ì„ ì°¾ì§€ ëª»í•¨, ë‹¨ìˆœ ì—°ê²°")
    return (len(words1), 0)


def merge_segment_lists(segments_list, chunk_info_list, overlap_seconds=25):
    """
    ì—¬ëŸ¬ ì²­í¬ì˜ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë³‘í•©

    Args:
        segments_list: ê° ì²­í¬ì˜ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸ [segments1, segments2, ...]
        chunk_info_list: ê° ì²­í¬ì˜ ì •ë³´ [(start_offset, end_offset), ...]
        overlap_seconds: ì¤‘ë³µ êµ¬ê°„ ê¸¸ì´ (ì´ˆ)

    Returns:
        list: ë³‘í•©ëœ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
    """
    if not segments_list or len(segments_list) == 0:
        return []

    if len(segments_list) == 1:
        return segments_list[0]

    logging.info(f"ğŸ”— ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ì‹œì‘: {len(segments_list)}ê°œ ì²­í¬")

    merged = []

    for chunk_idx, (segments, chunk_info) in enumerate(
        zip(segments_list, chunk_info_list)
    ):
        start_offset, end_offset = chunk_info

        if chunk_idx == 0:
            # ì²« ë²ˆì§¸ ì²­í¬ëŠ” ì „ì²´ ì¶”ê°€
            merged.extend(segments)
            logging.info(f"âœ… ì²­í¬ 0: {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€")
        else:
            # ì´ì „ ì²­í¬ì˜ ëë¶€ë¶„ê³¼ í˜„ì¬ ì²­í¬ì˜ ì‹œì‘ë¶€ë¶„ì—ì„œ ì¤‘ë³µ ì°¾ê¸°
            prev_chunk_start_offset = chunk_info_list[chunk_idx - 1][0]

            # ì´ì „ ì²­í¬ì˜ ë§ˆì§€ë§‰ Nê°œ ì„¸ê·¸ë¨¼íŠ¸ í…ìŠ¤íŠ¸
            prev_segments = segments_list[chunk_idx - 1]
            prev_text = " ".join([s.get("text", "") for s in prev_segments[-20:]])

            # í˜„ì¬ ì²­í¬ì˜ ì²˜ìŒ Nê°œ ì„¸ê·¸ë¨¼íŠ¸ í…ìŠ¤íŠ¸
            curr_text = " ".join([s.get("text", "") for s in segments[:20]])

            # ì¤‘ë³µ êµ¬ê°„ ì°¾ê¸°
            if prev_text and curr_text:
                prev_word_idx, curr_word_idx = find_best_overlap_match(
                    prev_text, curr_text
                )

                # ì¤‘ë³µì„ ê¸°ì¤€ìœ¼ë¡œ í˜„ì¬ ì²­í¬ì—ì„œ ì¶”ê°€í•  ë¶€ë¶„ ê²°ì •
                # í˜„ì¬ ì²­í¬ì˜ ì„¸ê·¸ë¨¼íŠ¸ ì¤‘ ì¤‘ë³µ ì´í›„ ë¶€ë¶„ë§Œ ì¶”ê°€

                # í˜„ì¬ ì²­í¬ ì„¸ê·¸ë¨¼íŠ¸ì˜ í…ìŠ¤íŠ¸ë¥¼ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ê³„ì‚°
                word_count = 0
                skip_until_idx = 0

                for idx, seg in enumerate(segments):
                    seg_words = len(seg.get("text", "").split())
                    word_count += seg_words
                    if word_count >= curr_word_idx:
                        skip_until_idx = idx + 1
                        break

                segments_to_add = segments[skip_until_idx:]
                logging.info(
                    f"âœ… ì²­í¬ {chunk_idx}: "
                    f"{len(segments_to_add)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€ "
                    f"(ì²˜ìŒ {skip_until_idx}ê°œ ì¤‘ë³µ ì œê±°)"
                )
            else:
                # ì¤‘ë³µì„ ì°¾ì§€ ëª»í•œ ê²½ìš°, ë‹¨ìˆœíˆ ì¤‘ë³µ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì œê±°
                segments_to_add = [
                    s for s in segments if s.get("start_time", 0) >= overlap_seconds
                ]
                logging.warning(
                    f"âš ï¸  ì²­í¬ {chunk_idx}: í…ìŠ¤íŠ¸ ë§¤ì¹­ ì‹¤íŒ¨, "
                    f"ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ {len(segments_to_add)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€"
                )

            # ì‹œê°„ ì˜¤í”„ì…‹ ì¡°ì •
            for seg in segments_to_add:
                if "start_time" in seg and seg["start_time"] is not None:
                    seg["start_time"] += start_offset
                if "end_time" in seg and seg["end_time"] is not None:
                    seg["end_time"] += start_offset

            merged.extend(segments_to_add)

    # ID ì¬í• ë‹¹
    for idx, seg in enumerate(merged, 1):
        seg["id"] = idx

    logging.info(f"âœ… ë³‘í•© ì™„ë£Œ: ì´ {len(merged)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
    return merged


def recognize_with_gemini_chunked(
    audio_path,
    task_id=None,
    audio_duration=None,
    chunk_duration_minutes=30,
    overlap_seconds=25,
    api_type="google_ai_studio",
):
    """
    ê¸´ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬ í›„ ë³‘í•©

    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        task_id: ì§„í–‰ ìƒí™© ì¶”ì ìš© ID
        audio_duration: ì˜¤ë””ì˜¤ ì´ ê¸¸ì´ (ì´ˆ)
        chunk_duration_minutes: ê° ì²­í¬ ê¸¸ì´ (ë¶„)
        overlap_seconds: ì²­í¬ ê°„ ì¤‘ë³µ ì‹œê°„ (ì´ˆ)
        api_type: "google_ai_studio" ë˜ëŠ” "vertex_ai"

    Returns:
        tuple: (segments, processing_time, detected_language)
    """
    from modules.utils import update_progress

    overall_start_time = time.time()

    try:
        if task_id:
            update_progress(task_id, "stt", 0, "ì˜¤ë””ì˜¤ ë¶„í•  ì¤‘...")

        # ì˜¤ë””ì˜¤ ë¶„í• 
        chunk_info_list = split_audio_with_overlap(
            audio_path,
            chunk_duration_minutes=chunk_duration_minutes,
            overlap_seconds=overlap_seconds,
        )

        if len(chunk_info_list) == 1 and chunk_info_list[0][0] == audio_path:
            # ë¶„í• ì´ í•„ìš” ì—†ëŠ” ê²½ìš° ê¸°ì¡´ í•¨ìˆ˜ ì‚¬ìš©
            logging.info("â­ï¸  ì²­í¬ ì²˜ë¦¬ ë¶ˆí•„ìš”, ì¼ë°˜ ì²˜ë¦¬ë¡œ ì „í™˜")
            return recognize_with_gemini(audio_path, task_id, audio_duration, api_type)

        # ê° ì²­í¬ ì²˜ë¦¬
        all_segments = []
        detected_languages = []
        temp_files = []

        for chunk_idx, (chunk_path, start_offset, end_offset) in enumerate(
            chunk_info_list
        ):
            if task_id:
                progress = int((chunk_idx / len(chunk_info_list)) * 90)
                update_progress(
                    task_id,
                    "stt",
                    progress,
                    f"ì²­í¬ {chunk_idx + 1}/{len(chunk_info_list)} ì²˜ë¦¬ ì¤‘...",
                )

            logging.info(
                f"ğŸ¯ ì²­í¬ {chunk_idx + 1}/{len(chunk_info_list)} ì²˜ë¦¬: "
                f"{start_offset:.2f}s ~ {end_offset:.2f}s"
            )

            # ì²­í¬ì˜ ê¸¸ì´ ê³„ì‚°
            chunk_duration = end_offset - start_offset

            # STT ìˆ˜í–‰
            segments, proc_time, lang = recognize_with_gemini(
                chunk_path,
                task_id=None,  # ê°œë³„ ì²­í¬ëŠ” ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ ì•ˆí•¨
                audio_duration=chunk_duration,
                api_type=api_type,
            )

            if segments:
                all_segments.append(segments)
                detected_languages.append(lang)

                # ì„ì‹œ íŒŒì¼ ê¸°ë¡ (ë‚˜ì¤‘ì— ì‚­ì œ)
                if chunk_path != audio_path:
                    temp_files.append(chunk_path)
            else:
                logging.error(f"âŒ ì²­í¬ {chunk_idx + 1} ì²˜ë¦¬ ì‹¤íŒ¨")

        # ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•©
        if task_id:
            update_progress(task_id, "stt", 95, "ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ì¤‘...")

        merged_segments = merge_segment_lists(
            all_segments,
            [(start, end) for _, start, end in chunk_info_list],
            overlap_seconds=overlap_seconds,
        )

        # ì–¸ì–´ ê²°ì • (ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ì–¸ì–´)
        if detected_languages:
            from collections import Counter

            detected_language = Counter(detected_languages).most_common(1)[0][0]
        else:
            detected_language = "unknown"

        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        for temp_file in temp_files:
            try:
                if os.path.exists(temp_file):
                    os.remove(temp_file)
                    logging.debug(f"ğŸ—‘ï¸  ì„ì‹œ íŒŒì¼ ì‚­ì œ: {temp_file}")
            except Exception as e:
                logging.warning(f"âš ï¸  ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {temp_file}, {e}")

        processing_time = time.time() - overall_start_time

        logging.info(
            f"âœ… ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ: {len(merged_segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸, "
            f"ì–¸ì–´: {detected_language} ({processing_time:.2f}ì´ˆ)"
        )

        if task_id:
            update_progress(
                task_id, "stt", 100, f"STT ì™„ë£Œ: {len(merged_segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸"
            )

        return merged_segments, processing_time, detected_language

    except Exception as e:
        logging.error(f"âŒ ì²­í¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback

        traceback.print_exc()

        # ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ fallback
        logging.info("ğŸ”„ ì¼ë°˜ ì²˜ë¦¬ë¡œ fallback")
        return recognize_with_gemini(audio_path, task_id, audio_duration, api_type)
