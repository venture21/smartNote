"""
ì˜ìƒ/ì˜¤ë””ì˜¤ ê²€ìƒ‰ ì—”ì§„ v0.3

ë‘ ê°€ì§€ ëª¨ë“œ ì œê³µ:
1. ì˜ìƒ ê²€ìƒ‰ ì—”ì§„: YouTube ë§í¬ ì…ë ¥ â†’ ë‹¤ìš´ë¡œë“œ â†’ STT â†’ íšŒì˜ë¡
2. ì˜¤ë””ì˜¤ ê²€ìƒ‰ ì—”ì§„: ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ â†’ STT â†’ íšŒì˜ë¡

ê¸°ëŠ¥:
- YouTube ì˜ìƒ ë‹¤ìš´ë¡œë“œ ë° MP3 ë³€í™˜
- ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ ì§€ì› (mp3, wav, m4a, flac, ogg)
- STT (Gemini / Clova)
- VectorStore ê¸°ë°˜ íšŒì˜ë¡ ì €ì¥ ë° ê²€ìƒ‰ (ChromaDB + Gemini Embedding)
- íšŒì˜ë¡ ìš”ì•½ ë° AI ì±„íŒ… (RAG ê¸°ë°˜)
- CSVë¡œ ì‘ì—… ì´ë ¥ ê´€ë¦¬ (ìºì‹±)
"""

from flask import Flask, render_template, request, jsonify, send_from_directory
import os
import pandas as pd
import json
import subprocess
from werkzeug.utils import secure_filename
from dotenv import load_dotenv
from myClovaSpeech import ClovaSpeechClient
from google import genai
from google.genai import types
import secrets
import yt_dlp
import logging
from datetime import datetime
import threading
import time
import hashlib
from mutagen import File as MutagenFile
import chromadb
from chromadb.config import Settings

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

app = Flask(__name__)
app.secret_key = secrets.token_hex(16)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)

# ì„¤ì •
MP4_FOLDER = "mp4"
MP3_FOLDER = "mp3"
CSV_FOLDER = "csv"
UPLOADS_FOLDER = "uploads"
CHROMA_DB_FOLDER = "chroma_db_v0.3"
YOUTUBE_HISTORY_CSV = os.path.join(CSV_FOLDER, "youtube_history_v0.3.csv")
AUDIO_HISTORY_CSV = os.path.join(CSV_FOLDER, "audio_history_v0.3.csv")

app.config["MAX_CONTENT_LENGTH"] = 500 * 1024 * 1024  # 500MB max

# í—ˆìš©ëœ ì˜¤ë””ì˜¤ íŒŒì¼ í™•ì¥ì
ALLOWED_AUDIO_EXTENSIONS = {'mp3', 'wav', 'm4a', 'flac', 'ogg', 'mp4', 'avi', 'mov', 'mkv'}

# í´ë” ìƒì„±
for folder in [MP4_FOLDER, MP3_FOLDER, CSV_FOLDER, UPLOADS_FOLDER, CHROMA_DB_FOLDER]:
    os.makedirs(folder, exist_ok=True)

# ì„¸ì…˜ë³„ ë°ì´í„° ì €ì¥
session_data = {}

# ì§„í–‰ ìƒí™© ì €ì¥
progress_data = {}

# ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
chroma_client = chromadb.PersistentClient(path=CHROMA_DB_FOLDER)

# ChromaDB ì»¬ë ‰ì…˜ (YouTubeì™€ Audio ë¶„ë¦¬)
youtube_collection = None
audio_collection = None


def allowed_file(filename):
    """í—ˆìš©ëœ íŒŒì¼ í™•ì¥ìì¸ì§€ í™•ì¸"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_AUDIO_EXTENSIONS


def calculate_file_hash(file_path):
    """íŒŒì¼ì˜ MD5 í•´ì‹œë¥¼ ê³„ì‚°í•˜ì—¬ ê³ ìœ  ID ìƒì„±"""
    hasher = hashlib.md5()
    with open(file_path, 'rb') as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hasher.update(chunk)
    return hasher.hexdigest()


def get_audio_duration(file_path):
    """ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ê¸¸ì´ë¥¼ ì´ˆ ë‹¨ìœ„ë¡œ ë°˜í™˜"""
    try:
        audio = MutagenFile(file_path)
        if audio is not None and hasattr(audio.info, 'length'):
            duration = audio.info.length
            logging.info(f"ğŸµ ì˜¤ë””ì˜¤ íŒŒì¼ ê¸¸ì´: {duration:.2f}ì´ˆ ({duration/60:.2f}ë¶„)")
            return duration
        else:
            logging.warning(f"âš ï¸ ì˜¤ë””ì˜¤ ê¸¸ì´ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            return 0.0
    except Exception as e:
        logging.error(f"âŒ ì˜¤ë””ì˜¤ ê¸¸ì´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return 0.0


def update_progress(task_id, step, progress, message):
    """ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸"""
    if task_id not in progress_data:
        progress_data[task_id] = {}

    progress_data[task_id][step] = {
        'progress': progress,
        'message': message,
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }
    logging.info(f"[{task_id}] {step}: {progress}% - {message}")


# YouTube ì´ë ¥ ë¡œë“œ
def load_youtube_history():
    """CSV íŒŒì¼ì—ì„œ YouTube ë‹¤ìš´ë¡œë“œ ì´ë ¥ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    if os.path.exists(YOUTUBE_HISTORY_CSV):
        try:
            df = pd.read_csv(YOUTUBE_HISTORY_CSV, encoding='utf-8-sig')
            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ë° ì¶”ê°€
            if 'summary' not in df.columns:
                df['summary'] = ''
            if 'stt_processing_time' not in df.columns:
                df['stt_processing_time'] = 0.0

            # NaN ê°’ ì²˜ë¦¬
            df['summary'] = df['summary'].fillna('')
            df['stt_processing_time'] = df['stt_processing_time'].fillna(0.0)
            df['view_count'] = df['view_count'].fillna(0)
            df['channel'] = df['channel'].fillna('Unknown')
            df['upload_date'] = df['upload_date'].fillna('')

            logging.info(f"ğŸ“‹ YouTube ì´ë ¥ ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í•­ëª©")
            return df
        except Exception as e:
            logging.error(f"YouTube ì´ë ¥ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return pd.DataFrame(columns=['youtube_url', 'video_id', 'title', 'channel', 'view_count', 'upload_date', 'mp3_path', 'segments_json', 'stt_service', 'stt_processing_time', 'created_at', 'summary'])
    else:
        return pd.DataFrame(columns=['youtube_url', 'video_id', 'title', 'channel', 'view_count', 'upload_date', 'mp3_path', 'segments_json', 'stt_service', 'stt_processing_time', 'created_at', 'summary'])


def save_youtube_history(df):
    """YouTube ì´ë ¥ì„ CSV íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        df.to_csv(YOUTUBE_HISTORY_CSV, index=False, encoding='utf-8-sig')
        logging.info(f"ğŸ’¾ YouTube ì´ë ¥ ì €ì¥ ì™„ë£Œ: {len(df)}ê°œ í•­ëª©")
    except Exception as e:
        logging.error(f"YouTube ì´ë ¥ ì €ì¥ ì˜¤ë¥˜: {e}")


# ì˜¤ë””ì˜¤ ì´ë ¥ ë¡œë“œ
def load_audio_history():
    """CSV íŒŒì¼ì—ì„œ ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ ì´ë ¥ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    if os.path.exists(AUDIO_HISTORY_CSV):
        try:
            df = pd.read_csv(AUDIO_HISTORY_CSV, encoding='utf-8-sig')
            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ë° ì¶”ê°€
            if 'summary' not in df.columns:
                df['summary'] = ''
            if 'stt_processing_time' not in df.columns:
                df['stt_processing_time'] = 0.0
            if 'audio_duration' not in df.columns:
                df['audio_duration'] = 0.0

            # NaN ê°’ ì²˜ë¦¬
            df['summary'] = df['summary'].fillna('')
            df['stt_processing_time'] = df['stt_processing_time'].fillna(0.0)
            df['audio_duration'] = df['audio_duration'].fillna(0.0)

            logging.info(f"ğŸ“‹ ì˜¤ë””ì˜¤ ì´ë ¥ ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í•­ëª©")
            return df
        except Exception as e:
            logging.error(f"ì˜¤ë””ì˜¤ ì´ë ¥ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return pd.DataFrame(columns=['file_hash', 'filename', 'file_path', 'file_size', 'audio_duration', 'segments_json', 'stt_service', 'stt_processing_time', 'created_at', 'summary'])
    else:
        return pd.DataFrame(columns=['file_hash', 'filename', 'file_path', 'file_size', 'audio_duration', 'segments_json', 'stt_service', 'stt_processing_time', 'created_at', 'summary'])


def save_audio_history(df):
    """ì˜¤ë””ì˜¤ ì´ë ¥ì„ CSV íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        df.to_csv(AUDIO_HISTORY_CSV, index=False, encoding='utf-8-sig')
        logging.info(f"ğŸ’¾ ì˜¤ë””ì˜¤ ì´ë ¥ ì €ì¥ ì™„ë£Œ: {len(df)}ê°œ í•­ëª©")
    except Exception as e:
        logging.error(f"ì˜¤ë””ì˜¤ ì´ë ¥ ì €ì¥ ì˜¤ë¥˜: {e}")


def get_gemini_client():
    """Gemini í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    api_key = os.environ.get("GOOGLE_API_KEY")
    if api_key:
        return genai.Client(api_key=api_key)
    else:
        return genai.Client()


def initialize_collections():
    """ChromaDB ì»¬ë ‰ì…˜ ì´ˆê¸°í™”"""
    global youtube_collection, audio_collection

    try:
        # YouTube ì»¬ë ‰ì…˜
        youtube_collection = chroma_client.get_or_create_collection(
            name="youtube_transcripts_v0.3",
            metadata={"description": "YouTube video transcripts with embeddings"}
        )

        # Audio ì»¬ë ‰ì…˜
        audio_collection = chroma_client.get_or_create_collection(
            name="audio_transcripts_v0.3",
            metadata={"description": "Audio file transcripts with embeddings"}
        )

        logging.info(f"âœ… ChromaDB ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ì™„ë£Œ")
        logging.info(f"   - YouTube ì»¬ë ‰ì…˜: {youtube_collection.count()} documents")
        logging.info(f"   - Audio ì»¬ë ‰ì…˜: {audio_collection.count()} documents")
    except Exception as e:
        logging.error(f"âŒ ChromaDB ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")


def get_gemini_embedding(text):
    """Geminië¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
    try:
        client = get_gemini_client()

        # Gemini embedding API ì‚¬ìš©
        result = client.models.embed_content(
            model="models/text-embedding-004",
            content=text
        )

        embedding = result['embedding']
        return embedding
    except Exception as e:
        logging.error(f"âŒ Gemini ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {e}")
        return None


def store_segments_in_vectordb(segments, source_id, source_type="youtube", filename=None):
    """
    ì„¸ê·¸ë¨¼íŠ¸ë¥¼ VectorDBì— ì €ì¥

    Args:
        segments: STTë¡œ ì¶”ì¶œëœ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
        source_id: YouTube video_id ë˜ëŠ” audio file_hash
        source_type: "youtube" ë˜ëŠ” "audio"
        filename: ì˜¤ë””ì˜¤ íŒŒì¼ëª… (ì˜¤ë””ì˜¤ì¼ ê²½ìš°)
    """
    try:
        collection = youtube_collection if source_type == "youtube" else audio_collection

        if not collection:
            logging.error("âŒ ChromaDB ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False

        # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ê°™ì€ source_id)
        try:
            existing_ids = collection.get(
                where={"source_id": source_id}
            )
            if existing_ids and existing_ids['ids']:
                collection.delete(ids=existing_ids['ids'])
                logging.info(f"ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ: {len(existing_ids['ids'])}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
        except Exception as e:
            logging.warning(f"ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")

        documents = []
        metadatas = []
        ids = []
        embeddings = []

        for segment in segments:
            # Document (content)
            text = segment['text']
            documents.append(text)

            # Metadata
            metadata = {
                "source_id": source_id,
                "source_type": source_type,
                "speaker": str(segment['speaker']),
                "start_time": float(segment['start_time']),
                "confidence": float(segment.get('confidence', 0.0)),
                "segment_id": int(segment['id'])
            }

            if source_type == "audio" and filename:
                metadata["filename"] = filename

            metadatas.append(metadata)

            # ID: source_id + segment_id
            doc_id = f"{source_id}_seg_{segment['id']}"
            ids.append(doc_id)

            # Embedding ìƒì„±
            embedding = get_gemini_embedding(text)
            if embedding:
                embeddings.append(embedding)
            else:
                logging.error(f"âŒ ì„¸ê·¸ë¨¼íŠ¸ {segment['id']} ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
                return False

        # ChromaDBì— ì €ì¥
        collection.add(
            ids=ids,
            documents=documents,
            metadatas=metadatas,
            embeddings=embeddings
        )

        logging.info(f"âœ… VectorDB ì €ì¥ ì™„ë£Œ: {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ (source: {source_id})")
        return True

    except Exception as e:
        logging.error(f"âŒ VectorDB ì €ì¥ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False


def search_vectordb(query, source_id=None, source_type=None, n_results=5):
    """
    VectorDBì—ì„œ ê²€ìƒ‰

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        source_id: íŠ¹ì • sourceë¡œ ì œí•œ (ì„ íƒ)
        source_type: "youtube" ë˜ëŠ” "audio" (ì„ íƒ)
        n_results: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜

    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    try:
        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embedding = get_gemini_embedding(query)
        if not query_embedding:
            logging.error("âŒ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
            return []

        # ê²€ìƒ‰í•  ì»¬ë ‰ì…˜ ê²°ì •
        collections_to_search = []
        if source_type == "youtube":
            collections_to_search = [youtube_collection]
        elif source_type == "audio":
            collections_to_search = [audio_collection]
        else:
            collections_to_search = [youtube_collection, audio_collection]

        all_results = []

        for collection in collections_to_search:
            if not collection:
                continue

            # where í•„í„° êµ¬ì„±
            where_filter = None
            if source_id:
                where_filter = {"source_id": source_id}

            # ê²€ìƒ‰ ìˆ˜í–‰
            results = collection.query(
                query_embeddings=[query_embedding],
                n_results=n_results,
                where=where_filter
            )

            # ê²°ê³¼ íŒŒì‹±
            if results and results['ids'] and len(results['ids']) > 0:
                for i in range(len(results['ids'][0])):
                    all_results.append({
                        'id': results['ids'][0][i],
                        'document': results['documents'][0][i],
                        'metadata': results['metadatas'][0][i],
                        'distance': results['distances'][0][i] if 'distances' in results else None
                    })

        # ê±°ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        all_results.sort(key=lambda x: x.get('distance', float('inf')))

        # ìƒìœ„ n_resultsê°œë§Œ ë°˜í™˜
        return all_results[:n_results]

    except Exception as e:
        logging.error(f"âŒ VectorDB ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return []


def download_youtube_audio_as_mp3(url, task_id=None):
    """
    YouTubeì—ì„œ ì˜¤ë””ì˜¤ë§Œ ë‹¤ìš´ë¡œë“œí•˜ì—¬ mp3ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Returns:
        dict: {
            'video_id': str,
            'title': str,
            'channel': str,
            'view_count': int,
            'upload_date': str,
            'mp3_path': str,
            'success': bool,
            'error': str (optional)
        }
    """
    try:
        if task_id:
            update_progress(task_id, 'download', 0, 'YouTube ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹œì‘')

        logging.info(f'ğŸµ YouTube ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {url}')

        # ì§„í–‰ë¥  ì½œë°± í•¨ìˆ˜
        def progress_hook(d):
            if task_id and d['status'] == 'downloading':
                downloaded = d.get('downloaded_bytes', 0)
                total = d.get('total_bytes') or d.get('total_bytes_estimate', 0)

                if total > 0:
                    percent = int((downloaded / total) * 100)
                    speed = d.get('speed', 0)
                    eta = d.get('eta', 0)

                    # ì†ë„ í¬ë§·íŒ…
                    if speed:
                        speed_mb = speed / (1024 * 1024)
                        speed_str = f"{speed_mb:.1f} MB/s"
                    else:
                        speed_str = "ê³„ì‚° ì¤‘..."

                    # ETA í¬ë§·íŒ…
                    if eta:
                        eta_min = eta // 60
                        eta_sec = eta % 60
                        eta_str = f"{int(eta_min)}:{int(eta_sec):02d}"
                    else:
                        eta_str = "ê³„ì‚° ì¤‘..."

                    message = f"ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì¤‘... {speed_str} (ë‚¨ì€ ì‹œê°„: {eta_str})"
                    update_progress(task_id, 'download', percent, message)
            elif task_id and d['status'] == 'finished':
                update_progress(task_id, 'download', 90, 'ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ, MP3 ë³€í™˜ ì¤‘...')
            elif task_id and d['status'] == 'processing':
                update_progress(task_id, 'download', 95, 'MP3 ë³€í™˜ ì¤‘...')

        ydl_opts = {
            'format': 'bestaudio/best',
            'outtmpl': os.path.join(MP3_FOLDER, '%(title).50s-%(id)s.%(ext)s'),
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': 'mp3',
                'preferredquality': '192',
            }],
            'progress_hooks': [progress_hook],
        }

        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info_dict = ydl.extract_info(url, download=True)
            video_id = info_dict.get('id', None)
            video_title = info_dict.get('title', None)
            channel = info_dict.get('channel', info_dict.get('uploader', 'Unknown'))
            view_count = info_dict.get('view_count', 0)
            upload_date = info_dict.get('upload_date', '')

            # upload_date í¬ë§· ë³€í™˜ (YYYYMMDD -> YYYY-MM-DD)
            if upload_date and len(upload_date) == 8:
                upload_date = f"{upload_date[:4]}-{upload_date[4:6]}-{upload_date[6:]}"

            # MP3 íŒŒì¼ ê²½ë¡œ ìƒì„± (yt-dlpê°€ ìƒì„±í•œ íŒŒì¼ëª… ê¸°ë°˜)
            # prepare_filenameì€ ì›ë³¸ í™•ì¥ìë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ .mp3ë¡œ êµì²´
            original_path = ydl.prepare_filename(info_dict)
            mp3_path = os.path.splitext(original_path)[0] + '.mp3'

        if not os.path.exists(mp3_path):
            if task_id:
                update_progress(task_id, 'download', 0, 'MP3 íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤')
            return {
                'success': False,
                'error': 'MP3 íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }

        logging.info(f'âœ… YouTube ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {mp3_path}')

        if task_id:
            update_progress(task_id, 'download', 100, 'YouTube ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ')

        return {
            'success': True,
            'video_id': video_id,
            'title': video_title,
            'channel': channel,
            'view_count': view_count,
            'upload_date': upload_date,
            'mp3_path': mp3_path
        }

    except Exception as e:
        logging.error(f"âŒ YouTube ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        if task_id:
            update_progress(task_id, 'download', 0, f'ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {str(e)}')
        return {
            'success': False,
            'error': str(e)
        }


def merge_consecutive_speaker_segments(segments):
    """ì—°ì†ì ìœ¼ë¡œ ë™ì¼í•œ í™”ìì˜ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í•©ì¹©ë‹ˆë‹¤."""
    if not segments:
        return []

    merged_segments = []
    current_segment = segments[0].copy()

    for next_segment in segments[1:]:
        if current_segment["speaker"] == next_segment["speaker"]:
            current_segment["text"] += " " + next_segment["text"]
        else:
            merged_segments.append(current_segment)
            current_segment = next_segment.copy()

    merged_segments.append(current_segment)
    return merged_segments


def recognize_with_clova(audio_path, task_id=None):
    """Clova Speech APIë¡œ ìŒì„± ì¸ì‹"""
    start_time = time.time()

    try:
        if task_id:
            update_progress(task_id, 'stt', 0, 'Clova STT ì‹œì‘')

        logging.info(f"ğŸ§ Clova Speech APIë¡œ ìŒì„± ì¸ì‹ ì¤‘: {audio_path}")

        res = ClovaSpeechClient().req_upload(
            file=audio_path, completion="sync", diarization={"enable": True}
        )

        if res.status_code == 200:
            result = res.json()
            logging.info("âœ… Clova ìŒì„± ì¸ì‹ ì™„ë£Œ")

            segments = result.get("segments", [])
            speaker_segments = []

            for segment in segments:
                speaker_label = segment["speaker"]["label"]
                text = segment["text"]
                confidence = segment.get("confidence", 0)
                start_time_ms = segment.get("start", 0)
                start_time_sec = start_time_ms / 1000.0

                speaker_segments.append(
                    {
                        "speaker": speaker_label,
                        "start_time": start_time_sec,
                        "confidence": confidence,
                        "text": text,
                    }
                )

            merged_segments = merge_consecutive_speaker_segments(speaker_segments)

            for idx, seg in enumerate(merged_segments):
                seg["id"] = idx

            end_time = time.time()
            processing_time = end_time - start_time

            if task_id:
                update_progress(task_id, 'stt', 100, f'Clova STT ì™„ë£Œ (ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ)')

            logging.info(f"â±ï¸ Clova STT ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")

            return {
                'segments': merged_segments,
                'processing_time': processing_time
            }
        else:
            end_time = time.time()
            processing_time = end_time - start_time

            logging.error(f"âŒ Clova ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {res.status_code}")
            if task_id:
                update_progress(task_id, 'stt', 0, 'Clova STT ì‹¤íŒ¨')
            return {
                'segments': None,
                'processing_time': processing_time
            }

    except Exception as e:
        end_time = time.time()
        processing_time = end_time - start_time

        logging.error(f"âŒ Clova ì˜¤ë¥˜ ë°œìƒ: {e}")
        if task_id:
            update_progress(task_id, 'stt', 0, 'Clova STT ì˜¤ë¥˜')
        return {
            'segments': None,
            'processing_time': processing_time
        }


def parse_mmss_to_seconds(time_str):
    """'ë¶„:ì´ˆ:ë°€ë¦¬ì´ˆ' í˜•íƒœì˜ ë¬¸ìì—´ì„ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        parts = time_str.split(":")
        if len(parts) == 3:
            minutes = int(parts[0])
            seconds = int(parts[1])
            milliseconds = int(parts[2])
            return minutes * 60 + seconds + milliseconds / 1000.0
        else:
            return 0.0
    except:
        return 0.0


def recognize_with_gemini(audio_path, task_id=None):
    """Google Gemini STT APIë¡œ ìŒì„± ì¸ì‹"""
    start_time = time.time()

    try:
        if task_id:
            update_progress(task_id, 'stt', 0, 'Gemini STT ì‹œì‘')

        logging.info(f"ğŸ§ Gemini STT APIë¡œ ìŒì„± ì¸ì‹ ì¤‘: {audio_path}")

        client = get_gemini_client()

        with open(audio_path, "rb") as f:
            file_bytes = f.read()

        file_ext = os.path.splitext(audio_path)[1].lower()
        mime_type_map = {
            ".wav": "audio/wav",
            ".mp3": "audio/mp3",
            ".m4a": "audio/mp4",
            ".flac": "audio/flac",
            ".ogg": "audio/ogg",
        }
        mime_type = mime_type_map.get(file_ext, "audio/mp3")

        prompt = """
ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ íšŒì˜ë¡ ì‘ì„±ìì…ë‹ˆë‹¤. ì œê³µëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë“£ê³  ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•´ ì£¼ì‹­ì‹œì˜¤:
1. ì „ì²´ ëŒ€í™”ë¥¼ ì •í™•í•˜ê²Œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
2. ê° ë°œí™”ì— ëŒ€í•´ í™”ìë¥¼ ìˆ«ìë¡œ êµ¬ë¶„í•©ë‹ˆë‹¤. ë°œí™”ìì˜ ë“±ì¥ ìˆœì„œëŒ€ë¡œ ë²ˆí˜¸ë¥¼ í• ë‹¹í•©ë‹ˆë‹¤.
3. ê° ë°œí™”ì— ëŒ€í•´ ìŒì„± ì¸ì‹ì˜ ì‹ ë¢°ë„ë¥¼ 0.0~1.0 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.
4. ìµœì¢… ê²°ê³¼ëŠ” ì•„ë˜ì˜ JSON í˜•ì‹ê³¼ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤. ê° JSON ê°ì²´ëŠ” 'speaker', 'start_time_mmss', 'confidence', 'text' í‚¤ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
5. start_time_mmssëŠ” "ë¶„:ì´ˆ:ë°€ë¦¬ì´ˆ" í˜•íƒœë¡œ ì¶œë ¥í•©ë‹ˆë‹¤. (ì˜ˆ: "0:05:200", "1:23:450")
6. ë°°ê²½ìŒì•…ê³¼ ë°œí™”ìì˜ ëª©ì†Œë¦¬ê°€ ì„ì¸ ê²½ìš° ëª©ì†Œë¦¬ë§Œ ì˜ êµ¬ë³„í•˜ì—¬ ê°€ì ¸ì˜¨ë‹¤.
7. speakerê°€ ë™ì¼í•œ ê²½ìš° í•˜ë‚˜ì˜ í–‰ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤. ë‹¨, ë¬¸ì¥ì´ 5ê°œë¥¼ ë„˜ì–´ê°ˆ ê²½ìš° ë‹¤ìŒ ëŒ€í™”ë¡œ ë¶„ë¦¬í•œë‹¤.


ì¶œë ¥ í˜•ì‹:
[
    {
        "speaker": 1,
        "start_time_mmss": "0:00:000",
        "confidence": 0.95,
        "text": "ì•ˆë…•í•˜ì„¸ìš”. íšŒì˜ë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤."
    },
    {
        "speaker": 2,
        "start_time_mmss": "0:05:200",
        "confidence": 0.92,
        "text": "ë„¤, ì¢‹ìŠµë‹ˆë‹¤."
    }
]

JSON ë°°ì—´ë§Œ ì¶œë ¥í•˜ê³ , ì¶”ê°€ ì„¤ëª…ì´ë‚˜ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
"""

        logging.info("ğŸ¤– Gemini 2.5 Proë¡œ ìŒì„± ì¸ì‹ ì¤‘...")

        response = client.models.generate_content(
            model="gemini-2.5-pro",
            contents=[
                prompt,
                types.Part.from_bytes(
                    data=file_bytes,
                    mime_type=mime_type,
                ),
            ],
        )

        logging.info("âœ… Gemini ìŒì„± ì¸ì‹ ì™„ë£Œ")

        cleaned_response = response.text.strip()
        cleaned_response = (
            cleaned_response.replace("```json", "").replace("```", "").strip()
        )

        result_list = json.loads(cleaned_response)

        normalized_segments = []
        for idx, segment in enumerate(result_list):
            time_mmss = segment.get("start_time_mmss", "0:00:000")
            start_time_seconds = parse_mmss_to_seconds(time_mmss)

            normalized_segments.append(
                {
                    "id": idx,
                    "speaker": segment.get("speaker", 1),
                    "start_time": start_time_seconds,
                    "confidence": segment.get("confidence", 0.0),
                    "text": segment.get("text", ""),
                }
            )

        end_time = time.time()
        processing_time = end_time - start_time

        if task_id:
            update_progress(task_id, 'stt', 100, f'Gemini STT ì™„ë£Œ (ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ)')

        logging.info(f"â±ï¸ Gemini STT ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")

        return {
            'segments': normalized_segments,
            'processing_time': processing_time
        }

    except Exception as e:
        end_time = time.time()
        processing_time = end_time - start_time

        logging.error(f"âŒ Gemini ì˜¤ë¥˜ ë°œìƒ: {e}")
        if task_id:
            update_progress(task_id, 'stt', 0, 'Gemini STT ì˜¤ë¥˜')
        import traceback
        traceback.print_exc()
        return {
            'segments': None,
            'processing_time': processing_time
        }


@app.route("/")
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return render_template("youtube_viewer_v0.3.html")


@app.route("/api/process-youtube", methods=["POST"])
def process_youtube():
    """
    YouTube URLì„ ì²˜ë¦¬í•˜ì—¬ íšŒì˜ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ìºì‹± ê¸°ëŠ¥ í¬í•¨.
    """
    try:
        data = request.get_json()
        youtube_url = data.get("youtube_url", "").strip()
        stt_service = data.get("stt_service", "gemini")

        if not youtube_url:
            return jsonify({
                "success": False,
                "error": "YouTube URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
            }), 400

        # ë¨¼ì € video_id ì¶”ì¶œ (ë‹¤ìš´ë¡œë“œ ì—†ì´ ì •ë³´ë§Œ)
        try:
            with yt_dlp.YoutubeDL({'quiet': True}) as ydl:
                info = ydl.extract_info(youtube_url, download=False)
                video_id = info.get('id', None)

                if not video_id:
                    return jsonify({
                        "success": False,
                        "error": "ìœ íš¨í•˜ì§€ ì•Šì€ YouTube URLì…ë‹ˆë‹¤."
                    }), 400
        except Exception as e:
            logging.error(f"URL íŒŒì‹± ì˜¤ë¥˜: {e}")
            return jsonify({
                "success": False,
                "error": f"YouTube URL íŒŒì‹± ì‹¤íŒ¨: {str(e)}"
            }), 400

        # ì´ë ¥ì—ì„œ í™•ì¸
        history_df = load_youtube_history()

        # video_idë¡œ ìºì‹œ í™•ì¸ (URL í˜•ì‹ê³¼ ë¬´ê´€)
        existing = history_df[history_df['video_id'] == video_id]

        if not existing.empty:
            # ìºì‹œëœ ë°ì´í„° ë¡œë“œ
            row = existing.iloc[0]

            logging.info(f"ğŸ“‚ ìºì‹œëœ ë°ì´í„° ë¡œë“œ: {row['title']}")

            # segments JSON íŒŒì‹±
            segments = json.loads(row['segments_json'])

            # ì„¸ì…˜ì— ì €ì¥
            session_id = request.remote_addr + "_" + secrets.token_hex(8)
            session_data[session_id] = {
                "segments": segments,
                "chat_history": [],
                "video_id": row['video_id'],  # ìš”ì•½ ì €ì¥ ì‹œ ì‚¬ìš©
                "source_type": "youtube"
            }

            # NaN ê°’ ì•ˆì „ ì²˜ë¦¬
            view_count = row.get('view_count', 0)
            if pd.isna(view_count):
                view_count = 0
            else:
                view_count = int(view_count)

            stt_processing_time = row.get('stt_processing_time', 0.0)
            if pd.isna(stt_processing_time):
                stt_processing_time = 0.0
            else:
                stt_processing_time = float(stt_processing_time)

            return jsonify({
                "success": True,
                "cached": True,
                "source_type": "youtube",
                "message": f"âœ… ì €ì¥ëœ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤: {row['title']}",
                "video_id": row['video_id'],
                "title": row['title'],
                "channel": row.get('channel', 'Unknown'),
                "view_count": view_count,
                "upload_date": row.get('upload_date', ''),
                "mp3_path": row.get('mp3_path', ''),
                "segments": segments,
                "total_segments": len(segments),
                "stt_service": row['stt_service'],
                "stt_processing_time": stt_processing_time,
                "session_id": session_id,
                "created_at": row['created_at'],
                "summary": row.get('summary', '')
            })

        # ìƒˆë¡œìš´ ì²˜ë¦¬
        logging.info(f"ğŸ†• ìƒˆë¡œìš´ YouTube URL ì²˜ë¦¬: {youtube_url}")

        # task_id ë° remote_addr ìƒì„± (request contextì—ì„œ ë¯¸ë¦¬ ì¶”ì¶œ)
        task_id = secrets.token_hex(16)
        remote_addr = request.remote_addr

        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬í•  í•¨ìˆ˜
        def process_in_background():
            try:
                # 1. YouTube ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ (mp3ë¡œ ì§ì ‘ ë³€í™˜)
                download_result = download_youtube_audio_as_mp3(youtube_url, task_id)
                if not download_result['success']:
                    update_progress(task_id, 'error', 0, f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {download_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                    return

                video_id = download_result['video_id']
                title = download_result['title']
                channel = download_result['channel']
                view_count = download_result['view_count']
                upload_date = download_result['upload_date']
                mp3_path = download_result['mp3_path']

                # 2. STT ì²˜ë¦¬
                stt_processing_time = 0.0
                segments = None

                if stt_service == "gemini":
                    result = recognize_with_gemini(mp3_path, task_id)
                    if result and isinstance(result, dict):
                        segments = result.get('segments')
                        stt_processing_time = result.get('processing_time', 0.0)
                else:
                    result = recognize_with_clova(mp3_path, task_id)
                    if result and isinstance(result, dict):
                        segments = result.get('segments')
                        stt_processing_time = result.get('processing_time', 0.0)

                if not segments:
                    update_progress(task_id, 'error', 0, f"{stt_service.upper()} STT ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                    return

                # 3. ì´ë ¥ì— ì €ì¥
                new_row = {
                    'youtube_url': youtube_url,
                    'video_id': video_id,
                    'title': title,
                    'channel': channel,
                    'view_count': view_count,
                    'upload_date': upload_date,
                    'mp3_path': mp3_path,
                    'segments_json': json.dumps(segments, ensure_ascii=False),
                    'stt_service': stt_service,
                    'stt_processing_time': stt_processing_time,
                    'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'summary': ''
                }

                history_df = load_youtube_history()
                history_df = pd.concat([history_df, pd.DataFrame([new_row])], ignore_index=True)
                save_youtube_history(history_df)

                # 3-1. VectorDBì— ì €ì¥
                logging.info(f"ğŸ“¦ VectorDBì— ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥ ì¤‘...")
                vectordb_success = store_segments_in_vectordb(
                    segments=segments,
                    source_id=video_id,
                    source_type="youtube",
                    filename=None
                )
                if vectordb_success:
                    logging.info(f"âœ… VectorDB ì €ì¥ ì™„ë£Œ")
                else:
                    logging.warning(f"âš ï¸ VectorDB ì €ì¥ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰)")

                # 4. ì„¸ì…˜ì— ì €ì¥
                session_id = remote_addr + "_" + secrets.token_hex(8)
                session_data[session_id] = {
                    "segments": segments,
                    "chat_history": [],
                    "video_id": video_id,
                    "source_type": "youtube"
                }

                # ì™„ë£Œ ìƒíƒœ ì €ì¥
                progress_data[task_id]['completed'] = True
                progress_data[task_id]['result'] = {
                    "success": True,
                    "source_type": "youtube",
                    "video_id": video_id,
                    "title": title,
                    "channel": channel,
                    "view_count": view_count,
                    "upload_date": upload_date,
                    "mp3_path": mp3_path,
                    "segments": segments,
                    "total_segments": len(segments),
                    "stt_service": stt_service,
                    "stt_processing_time": stt_processing_time,
                    "session_id": session_id,
                    "created_at": new_row['created_at']
                }

                logging.info(f"âœ… ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ì™„ë£Œ: {title}")

            except Exception as e:
                import traceback
                traceback.print_exc()
                update_progress(task_id, 'error', 0, f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

        # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘
        thread = threading.Thread(target=process_in_background)
        thread.daemon = True
        thread.start()

        # ì¦‰ì‹œ task_id ë°˜í™˜
        return jsonify({
            "success": True,
            "processing": True,
            "task_id": task_id,
            "message": "ì²˜ë¦¬ë¥¼ ì‹œì‘í–ˆìŠµë‹ˆë‹¤. ì§„í–‰ ìƒí™©ì„ í™•ì¸í•˜ì„¸ìš”."
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            "success": False,
            "error": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        }), 500


@app.route("/api/process-audio", methods=["POST"])
def process_audio():
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ íšŒì˜ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ìºì‹± ê¸°ëŠ¥ í¬í•¨.
    """
    try:
        # íŒŒì¼ í™•ì¸
        if 'audio_file' not in request.files:
            return jsonify({
                "success": False,
                "error": "ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."
            }), 400

        file = request.files['audio_file']
        stt_service = request.form.get('stt_service', 'gemini')

        if file.filename == '':
            return jsonify({
                "success": False,
                "error": "íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            }), 400

        if not allowed_file(file.filename):
            return jsonify({
                "success": False,
                "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. í—ˆìš©ëœ í˜•ì‹: {', '.join(ALLOWED_AUDIO_EXTENSIONS)}"
            }), 400

        # íŒŒì¼ ì €ì¥
        filename = secure_filename(file.filename)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        unique_filename = f"{timestamp}_{filename}"
        file_path = os.path.join(UPLOADS_FOLDER, unique_filename)
        file.save(file_path)

        logging.info(f"ğŸ“ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {file_path}")

        # íŒŒì¼ í•´ì‹œ ê³„ì‚°
        file_hash = calculate_file_hash(file_path)
        file_size = os.path.getsize(file_path)

        # ì˜¤ë””ì˜¤ ê¸¸ì´ ì¶”ì¶œ
        audio_duration = get_audio_duration(file_path)

        # ì´ë ¥ì—ì„œ í™•ì¸ (íŒŒì¼ í•´ì‹œë¡œ ìºì‹œ í™•ì¸)
        history_df = load_audio_history()
        existing = history_df[history_df['file_hash'] == file_hash]

        if not existing.empty:
            # ìºì‹œëœ ë°ì´í„° ë¡œë“œ
            row = existing.iloc[0]

            logging.info(f"ğŸ“‚ ìºì‹œëœ ì˜¤ë””ì˜¤ ë°ì´í„° ë¡œë“œ: {row['filename']}")

            # segments JSON íŒŒì‹±
            segments = json.loads(row['segments_json'])

            # ì„¸ì…˜ì— ì €ì¥
            session_id = request.remote_addr + "_" + secrets.token_hex(8)
            session_data[session_id] = {
                "segments": segments,
                "chat_history": [],
                "file_hash": row['file_hash'],
                "source_type": "audio"
            }

            stt_processing_time = row.get('stt_processing_time', 0.0)
            if pd.isna(stt_processing_time):
                stt_processing_time = 0.0
            else:
                stt_processing_time = float(stt_processing_time)

            audio_duration = row.get('audio_duration', 0.0)
            if pd.isna(audio_duration):
                audio_duration = 0.0
            else:
                audio_duration = float(audio_duration)

            return jsonify({
                "success": True,
                "cached": True,
                "source_type": "audio",
                "message": f"âœ… ì €ì¥ëœ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤: {row['filename']}",
                "file_hash": row['file_hash'],
                "filename": row['filename'],
                "file_path": row['file_path'],
                "file_size": int(row['file_size']),
                "audio_duration": audio_duration,
                "segments": segments,
                "total_segments": len(segments),
                "stt_service": row['stt_service'],
                "stt_processing_time": stt_processing_time,
                "session_id": session_id,
                "created_at": row['created_at'],
                "summary": row.get('summary', '')
            })

        # ìƒˆë¡œìš´ ì²˜ë¦¬
        logging.info(f"ğŸ†• ìƒˆë¡œìš´ ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬: {filename}")

        # task_id ë° remote_addr ìƒì„±
        task_id = secrets.token_hex(16)
        remote_addr = request.remote_addr

        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬í•  í•¨ìˆ˜
        def process_in_background():
            try:
                # STT ì²˜ë¦¬
                stt_processing_time = 0.0
                segments = None

                if stt_service == "gemini":
                    result = recognize_with_gemini(file_path, task_id)
                    if result and isinstance(result, dict):
                        segments = result.get('segments')
                        stt_processing_time = result.get('processing_time', 0.0)
                else:
                    result = recognize_with_clova(file_path, task_id)
                    if result and isinstance(result, dict):
                        segments = result.get('segments')
                        stt_processing_time = result.get('processing_time', 0.0)

                if not segments:
                    update_progress(task_id, 'error', 0, f"{stt_service.upper()} STT ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                    return

                # ì´ë ¥ì— ì €ì¥
                new_row = {
                    'file_hash': file_hash,
                    'filename': filename,
                    'file_path': file_path,
                    'file_size': file_size,
                    'audio_duration': audio_duration,
                    'segments_json': json.dumps(segments, ensure_ascii=False),
                    'stt_service': stt_service,
                    'stt_processing_time': stt_processing_time,
                    'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'summary': ''
                }

                history_df = load_audio_history()
                history_df = pd.concat([history_df, pd.DataFrame([new_row])], ignore_index=True)
                save_audio_history(history_df)

                # VectorDBì— ì €ì¥
                logging.info(f"ğŸ“¦ VectorDBì— ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥ ì¤‘...")
                vectordb_success = store_segments_in_vectordb(
                    segments=segments,
                    source_id=file_hash,
                    source_type="audio",
                    filename=filename
                )
                if vectordb_success:
                    logging.info(f"âœ… VectorDB ì €ì¥ ì™„ë£Œ")
                else:
                    logging.warning(f"âš ï¸ VectorDB ì €ì¥ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰)")

                # ì„¸ì…˜ì— ì €ì¥
                session_id = remote_addr + "_" + secrets.token_hex(8)
                session_data[session_id] = {
                    "segments": segments,
                    "chat_history": [],
                    "file_hash": file_hash,
                    "source_type": "audio"
                }

                # ì™„ë£Œ ìƒíƒœ ì €ì¥
                progress_data[task_id]['completed'] = True
                progress_data[task_id]['result'] = {
                    "success": True,
                    "source_type": "audio",
                    "file_hash": file_hash,
                    "filename": filename,
                    "file_path": file_path,
                    "file_size": file_size,
                    "audio_duration": audio_duration,
                    "segments": segments,
                    "total_segments": len(segments),
                    "stt_service": stt_service,
                    "stt_processing_time": stt_processing_time,
                    "session_id": session_id,
                    "created_at": new_row['created_at']
                }

                logging.info(f"âœ… ë°±ê·¸ë¼ìš´ë“œ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ: {filename}")

            except Exception as e:
                import traceback
                traceback.print_exc()
                update_progress(task_id, 'error', 0, f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

        # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘
        thread = threading.Thread(target=process_in_background)
        thread.daemon = True
        thread.start()

        # ì¦‰ì‹œ task_id ë°˜í™˜
        return jsonify({
            "success": True,
            "processing": True,
            "task_id": task_id,
            "message": "ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ë¥¼ ì‹œì‘í–ˆìŠµë‹ˆë‹¤. ì§„í–‰ ìƒí™©ì„ í™•ì¸í•˜ì„¸ìš”."
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            "success": False,
            "error": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        }), 500


@app.route("/uploads/<path:filename>")
def serve_audio(filename):
    """ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼ ì œê³µ"""
    return send_from_directory(UPLOADS_FOLDER, filename)


@app.route("/mp3/<path:filename>")
def serve_mp3(filename):
    """MP3 íŒŒì¼ ì œê³µ"""
    return send_from_directory(MP3_FOLDER, filename)


@app.route("/api/summarize", methods=["POST"])
def summarize_transcript():
    """íšŒì˜ë¡ ìš”ì•½ API"""
    try:
        data = request.get_json()
        segments = data.get("segments")
        session_id = data.get("session_id")

        if not segments and session_id and session_id in session_data:
            segments = session_data[session_id]["segments"]

        if not segments:
            return jsonify({
                "success": False,
                "error": "ìš”ì•½í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            }), 400

        transcript_text = "\n\n".join([
            f"í™”ì {seg['speaker']}: {seg['text']}"
            for seg in segments
        ])

        client = get_gemini_client()

        prompt = f"""ë‹¤ìŒì€ íšŒì˜ë¡ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”.

ìš”ì•½ ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ í¬í•¨í•´ ì£¼ì„¸ìš”:
1. ì£¼ìš” ë…¼ì˜ ì£¼ì œ
2. ì£¼ìš” ê²°ì • ì‚¬í•­
3. ì•¡ì…˜ ì•„ì´í…œ (ìˆëŠ” ê²½ìš°)
4. ì¤‘ìš”í•œ ë°œì–¸ì´ë‚˜ ì˜ê²¬

íšŒì˜ë¡:
{transcript_text}

ìš”ì•½ì„ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”."""

        logging.info("ğŸ¤– Geminië¡œ ìš”ì•½ ìƒì„± ì¤‘...")

        response = client.models.generate_content(
            model="gemini-2.5-pro",
            contents=prompt,
        )

        summary = response.text.strip()
        logging.info("âœ… ìš”ì•½ ìƒì„± ì™„ë£Œ")

        # CSVì— ìš”ì•½ ì €ì¥
        if session_id and session_id in session_data:
            source_type = session_data[session_id].get("source_type")

            if source_type == "youtube":
                video_id = session_data[session_id].get("video_id")
                if video_id:
                    try:
                        history_df = load_youtube_history()
                        mask = history_df['video_id'] == video_id
                        if mask.any():
                            history_df.loc[mask, 'summary'] = summary
                            save_youtube_history(history_df)
                            logging.info(f"ğŸ’¾ ìš”ì•½ì´ YouTube CSVì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤ (video_id: {video_id})")
                    except Exception as e:
                        logging.error(f"ìš”ì•½ ì €ì¥ ì˜¤ë¥˜: {e}")

            elif source_type == "audio":
                file_hash = session_data[session_id].get("file_hash")
                if file_hash:
                    try:
                        history_df = load_audio_history()
                        mask = history_df['file_hash'] == file_hash
                        if mask.any():
                            history_df.loc[mask, 'summary'] = summary
                            save_audio_history(history_df)
                            logging.info(f"ğŸ’¾ ìš”ì•½ì´ ì˜¤ë””ì˜¤ CSVì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤ (file_hash: {file_hash})")
                    except Exception as e:
                        logging.error(f"ìš”ì•½ ì €ì¥ ì˜¤ë¥˜: {e}")

        return jsonify({
            "success": True,
            "summary": summary
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            "success": False,
            "error": f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        }), 500


@app.route("/api/chat", methods=["POST"])
def chat_with_transcript():
    """íšŒì˜ë¡ ê¸°ë°˜ ì±„íŒ… API (RAG)"""
    try:
        data = request.get_json()
        user_message = data.get("message", "").strip()

        if not user_message:
            return jsonify({
                "success": False,
                "error": "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
            }), 400

        session_id = data.get("session_id")
        chat_history = data.get("chat_history", [])

        if not session_id or session_id not in session_data:
            return jsonify({
                "success": False,
                "error": "ì„¸ì…˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            }), 400

        session_info = session_data[session_id]
        source_type = session_info.get("source_type")
        chat_history = session_info.get("chat_history", [])

        # source_id ê°€ì ¸ì˜¤ê¸°
        if source_type == "youtube":
            source_id = session_info.get("video_id")
        elif source_type == "audio":
            source_id = session_info.get("file_hash")
        else:
            return jsonify({
                "success": False,
                "error": "ì•Œ ìˆ˜ ì—†ëŠ” ì†ŒìŠ¤ íƒ€ì…ì…ë‹ˆë‹¤."
            }), 400

        # VectorDBì—ì„œ ê´€ë ¨ ì„¸ê·¸ë¨¼íŠ¸ ê²€ìƒ‰ (RAG)
        logging.info(f"ğŸ” VectorDB ê²€ìƒ‰: {user_message}")
        search_results = search_vectordb(
            query=user_message,
            source_id=source_id,
            source_type=source_type,
            n_results=5
        )

        if not search_results:
            return jsonify({
                "success": False,
                "error": "ê´€ë ¨ íšŒì˜ë¡ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }), 400

        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
        context_text = "\n\n".join([
            f"í™”ì {result['metadata']['speaker']} ({result['metadata']['start_time']:.1f}ì´ˆ): {result['document']}"
            for result in search_results
        ])

        logging.info(f"ğŸ“ ê²€ìƒ‰ëœ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(search_results)}")

        # ì´ì „ ëŒ€í™” ë‚´ì—­
        history_text = ""
        if chat_history:
            history_text = "\n\nì´ì „ ëŒ€í™” ë‚´ì—­:\n"
            for hist in chat_history[-5:]:
                history_text += f"ì‚¬ìš©ì: {hist['user']}\n"
                history_text += f"AI: {hist['assistant']}\n\n"

        client = get_gemini_client()

        prompt = f"""ë‹¹ì‹ ì€ íšŒì˜ë¡ ë¶„ì„ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒì€ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ íšŒì˜ë¡ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”.

ê´€ë ¨ íšŒì˜ë¡ ë‚´ìš©:
{context_text}
{history_text}
ì‚¬ìš©ì ì§ˆë¬¸: {user_message}

ë‹µë³€ ì‹œ ë‹¤ìŒì„ ìœ ì˜í•´ ì£¼ì„¸ìš”:
1. ì œê³µëœ íšŒì˜ë¡ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
2. í•„ìš”í•œ ê²½ìš° í™”ìì™€ ì‹œê°„ ì •ë³´ë¥¼ í¬í•¨í•´ ì£¼ì„¸ìš”.
3. ì œê³µëœ ë‚´ìš©ì— ì—†ëŠ” ê²ƒì€ ì¶”ì¸¡í•˜ì§€ ë§ê³  "ì œê³µëœ íšŒì˜ë¡ì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
4. ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."""

        logging.info(f"ğŸ¤– ì‚¬ìš©ì ì§ˆë¬¸: {user_message}")

        response = client.models.generate_content(
            model="gemini-2.5-pro",
            contents=prompt,
        )

        assistant_response = response.text.strip()
        logging.info(f"âœ… AI ì‘ë‹µ ìƒì„± ì™„ë£Œ (RAG ê¸°ë°˜)")

        chat_history.append({
            "user": user_message,
            "assistant": assistant_response
        })

        session_data[session_id]["chat_history"] = chat_history

        return jsonify({
            "success": True,
            "response": assistant_response,
            "chat_history": chat_history,
            "search_results": len(search_results)  # ë””ë²„ê¹…ìš©
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            "success": False,
            "error": f"ì±„íŒ… ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        }), 500


@app.route("/api/history", methods=["GET"])
def get_history():
    """ì²˜ë¦¬ ì´ë ¥ ì¡°íšŒ API"""
    try:
        youtube_history = load_youtube_history()
        audio_history = load_audio_history()

        # DataFrameì„ dict ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        youtube_list = youtube_history.to_dict('records')
        audio_list = audio_history.to_dict('records')

        return jsonify({
            "success": True,
            "youtube_history": youtube_list,
            "audio_history": audio_list,
            "total_youtube": len(youtube_list),
            "total_audio": len(audio_list)
        })
    except Exception as e:
        logging.error(f"ì´ë ¥ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route("/api/progress/<task_id>", methods=["GET"])
def get_progress(task_id):
    """ì§„í–‰ ìƒí™© ì¡°íšŒ API"""
    try:
        if task_id not in progress_data:
            return jsonify({
                "success": False,
                "error": "ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }), 404

        return jsonify({
            "success": True,
            "task_id": task_id,
            "progress": progress_data[task_id]
        })
    except Exception as e:
        logging.error(f"ì§„í–‰ ìƒí™© ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ¬ ì˜ìƒ/ì˜¤ë””ì˜¤ ê²€ìƒ‰ ì—”ì§„ v0.2 ì‹œì‘")
    print("=" * 60)
    print("URL: http://localhost:5002")
    print("=" * 60)
    print("ê¸°ëŠ¥:")
    print("  [ì˜ìƒ ê²€ìƒ‰ ì—”ì§„]")
    print("  - YouTube ì˜ìƒ ë‹¤ìš´ë¡œë“œ (mp4 í´ë”)")
    print("  - MP3 ë³€í™˜ (mp3 í´ë”)")
    print("  - STT íšŒì˜ë¡ ìƒì„±")
    print("")
    print("  [ì˜¤ë””ì˜¤ ê²€ìƒ‰ ì—”ì§„]")
    print("  - ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ (uploads í´ë”)")
    print("  - STT íšŒì˜ë¡ ìƒì„±")
    print("")
    print("  [ê³µí†µ ê¸°ëŠ¥]")
    print("  - íšŒì˜ë¡ ìš”ì•½")
    print("  - AI ì±„íŒ…")
    print("  - ì²˜ë¦¬ ì´ë ¥ ìºì‹± (CSV)")
    print("=" * 60)

    app.run(host="0.0.0.0", port=5002, debug=True)
